{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis with an RNN\n",
    "\n",
    "In this notebook, you'll implement a recurrent neural network that performs sentiment analysis. Using an RNN rather than a feedfoward network is more accurate since we can include information about the *sequence* of words. Here we'll use a dataset of movie reviews, accompanied by labels.\n",
    "\n",
    "The architecture for this network is shown below.\n",
    "\n",
    "<img src=\"assets/network_diagram.png\" width=400px>\n",
    "\n",
    "Here, we'll pass in words to an embedding layer. We need an embedding layer because we have tens of thousands of words, so we'll need a more efficient representation for our input data than one-hot encoded vectors. You should have seen this before from the word2vec lesson. You can actually train up an embedding with word2vec and use it here. But it's good enough to just have an embedding layer and let the network learn the embedding table on it's own.\n",
    "\n",
    "From the embedding layer, the new representations will be passed to LSTM cells. These will add recurrent connections to the network so we can include information about the sequence of words in the data. Finally, the LSTM cells will go to a sigmoid output layer here. We're using the sigmoid because we're trying to predict if this text has positive or negative sentiment. The output layer will just be a single unit then, with a sigmoid activation function.\n",
    "\n",
    "We don't care about the sigmoid outputs except for the very last one, we can ignore the rest. We'll calculate the cost from the output of the last step and the training label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./sentiment-network/reviews.txt', 'r') as f:\n",
    "    reviews = f.read()\n",
    "with open('./sentiment-network/labels.txt', 'r') as f:\n",
    "    labels = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bromwell high is a cartoon comedy . it ran at the same time as some other programs about school life  such as  teachers  . my   years in the teaching profession lead me to believe that bromwell high  s satire is much closer to reality than is  teachers  . the scramble to survive financially  the insightful students who can see right through their pathetic teachers  pomp  the pettiness of the whole situation  all remind me of the schools i knew and their students . when i saw the episode in which a student repeatedly tried to burn down the school  i immediately recalled . . . . . . . . . at . . . . . . . . . . high . a classic line inspector i  m here to sack one of your teachers . student welcome to bromwell high . i expect that many adults of my age think that bromwell high is far fetched . what a pity that it isn  t   \\nstory of a man who has unnatural feelings for a pig . starts out with a opening scene that is a terrific example of absurd comedy . a formal orchestra audience is turned into an insane  violent mob by the crazy chantings of it  s singers . unfortunately it stays absurd the whole time with no general narrative eventually making it just too off putting . even those from the era should be turned off . the cryptic dialogue would make shakespeare seem easy to a third grader . on a technical level it  s better than you might think with some good cinematography by future great vilmos zsigmond . future stars sally kirkland and frederic forrest can be seen briefly .  \\nhomelessness  or houselessness as george carlin stated  has been an issue for years but never a plan to help those on the street that were once considered human who did everything from going to school  work  or vote for the matter . most people think of the homeless as just a lost cause while worrying about things such as racism  the war on iraq  pressuring kids to succeed  technology  the elections  inflation  or worrying if they  ll be next to end up on the streets .  br    br   but what if y'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews[:2000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing\n",
    "\n",
    "The first step when building a neural network model is getting your data into the proper form to feed into the network. Since we're using embedding layers, we'll need to encode each word with an integer. We'll also want to clean it up a bit.\n",
    "\n",
    "You can see an example of the reviews data above. We'll want to get rid of those periods. Also, you might notice that the reviews are delimited with newlines `\\n`. To deal with those, I'm going to split the text into each review using `\\n` as the delimiter. Then I can combined all the reviews back together into one big string.\n",
    "\n",
    "First, let's remove all punctuation. Then get all the text without the newlines and split it into individual words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from string import punctuation\n",
    "# Only keep not-punctuation characters\n",
    "all_text = ''.join([c for c in reviews if c not in punctuation])\n",
    "# Remove the newline '\\n'\n",
    "reviews = all_text.split('\\n')\n",
    "\n",
    "# Split the text into individual words\n",
    "all_text = ' '.join(reviews)\n",
    "words = all_text.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bromwell high is a cartoon comedy  it ran at the same time as some other programs about school life  such as  teachers   my   years in the teaching profession lead me to believe that bromwell high  s satire is much closer to reality than is  teachers   the scramble to survive financially  the insightful students who can see right through their pathetic teachers  pomp  the pettiness of the whole situation  all remind me of the schools i knew and their students  when i saw the episode in which a student repeatedly tried to burn down the school  i immediately recalled          at           high  a classic line inspector i  m here to sack one of your teachers  student welcome to bromwell high  i expect that many adults of my age think that bromwell high is far fetched  what a pity that it isn  t    story of a man who has unnatural feelings for a pig  starts out with a opening scene that is a terrific example of absurd comedy  a formal orchestra audience is turned into an insane  violent mob by the crazy chantings of it  s singers  unfortunately it stays absurd the whole time with no general narrative eventually making it just too off putting  even those from the era should be turned off  the cryptic dialogue would make shakespeare seem easy to a third grader  on a technical level it  s better than you might think with some good cinematography by future great vilmos zsigmond  future stars sally kirkland and frederic forrest can be seen briefly    homelessness  or houselessness as george carlin stated  has been an issue for years but never a plan to help those on the street that were once considered human who did everything from going to school  work  or vote for the matter  most people think of the homeless as just a lost cause while worrying about things such as racism  the war on iraq  pressuring kids to succeed  technology  the elections  inflation  or worrying if they  ll be next to end up on the streets   br    br   but what if you were given a bet to live on the st'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_text[:2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bromwell',\n",
       " 'high',\n",
       " 'is',\n",
       " 'a',\n",
       " 'cartoon',\n",
       " 'comedy',\n",
       " 'it',\n",
       " 'ran',\n",
       " 'at',\n",
       " 'the',\n",
       " 'same',\n",
       " 'time',\n",
       " 'as',\n",
       " 'some',\n",
       " 'other',\n",
       " 'programs',\n",
       " 'about',\n",
       " 'school',\n",
       " 'life',\n",
       " 'such',\n",
       " 'as',\n",
       " 'teachers',\n",
       " 'my',\n",
       " 'years',\n",
       " 'in',\n",
       " 'the',\n",
       " 'teaching',\n",
       " 'profession',\n",
       " 'lead',\n",
       " 'me',\n",
       " 'to',\n",
       " 'believe',\n",
       " 'that',\n",
       " 'bromwell',\n",
       " 'high',\n",
       " 's',\n",
       " 'satire',\n",
       " 'is',\n",
       " 'much',\n",
       " 'closer',\n",
       " 'to',\n",
       " 'reality',\n",
       " 'than',\n",
       " 'is',\n",
       " 'teachers',\n",
       " 'the',\n",
       " 'scramble',\n",
       " 'to',\n",
       " 'survive',\n",
       " 'financially',\n",
       " 'the',\n",
       " 'insightful',\n",
       " 'students',\n",
       " 'who',\n",
       " 'can',\n",
       " 'see',\n",
       " 'right',\n",
       " 'through',\n",
       " 'their',\n",
       " 'pathetic',\n",
       " 'teachers',\n",
       " 'pomp',\n",
       " 'the',\n",
       " 'pettiness',\n",
       " 'of',\n",
       " 'the',\n",
       " 'whole',\n",
       " 'situation',\n",
       " 'all',\n",
       " 'remind',\n",
       " 'me',\n",
       " 'of',\n",
       " 'the',\n",
       " 'schools',\n",
       " 'i',\n",
       " 'knew',\n",
       " 'and',\n",
       " 'their',\n",
       " 'students',\n",
       " 'when',\n",
       " 'i',\n",
       " 'saw',\n",
       " 'the',\n",
       " 'episode',\n",
       " 'in',\n",
       " 'which',\n",
       " 'a',\n",
       " 'student',\n",
       " 'repeatedly',\n",
       " 'tried',\n",
       " 'to',\n",
       " 'burn',\n",
       " 'down',\n",
       " 'the',\n",
       " 'school',\n",
       " 'i',\n",
       " 'immediately',\n",
       " 'recalled',\n",
       " 'at',\n",
       " 'high']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words[:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding the words\n",
    "\n",
    "The embedding lookup requires that we pass in integers to our network. The easiest way to do this is to create dictionaries that map the words in the vocabulary to integers. Then we can convert each of our reviews into integers so they can be passed into the network.\n",
    "\n",
    "> **Exercise:** Now you're going to encode the words with integers. Build a dictionary that maps words to integers. Later we're going to pad our input vectors with zeros, so make sure the integers **start at 1, not 0**.\n",
    "> Also, convert the reviews to integers and store the reviews in a new list called `reviews_ints`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create your dictionary that maps vocab words to integers here\n",
    "\n",
    "from collections import Counter\n",
    "# Create an unsorted counter for the list of words\n",
    "counts = Counter(words)\n",
    "# Sort the counter in descending order\n",
    "vocab = sorted(counts, key = counts.get, reverse=True)\n",
    "# Map vocab words to integers\n",
    "vocab_to_int = {word: ii for ii, word in enumerate(vocab, 1)} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Convert the reviews to integers, same shape as reviews list, but with integers\n",
    "reviews_ints = []\n",
    "for review in reviews:\n",
    "    reviews_ints.append([vocab_to_int[word] for word in review.split()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding the labels\n",
    "\n",
    "Our labels are \"positive\" or \"negative\". To use these labels in our network, we need to convert them to 0 and 1.\n",
    "\n",
    "> **Exercise:** Convert labels from `positive` and `negative` to 1 and 0, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Convert labels to 1s and 0s for 'positive' and 'negative'\n",
    "labels = labels.split('\\n')\n",
    "labels = np.array([1 if label == 'positive' else 0 for label in labels])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you built `labels` correctly, you should see the next output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zero-length reviews: 1\n",
      "Maximum review length: 2514\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "review_lens = Counter([len(x) for x in reviews_ints])\n",
    "print(\"Zero-length reviews: {}\".format(review_lens[0]))\n",
    "print(\"Maximum review length: {}\".format(max(review_lens)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, a couple issues here. We seem to have one review with zero length. And, the maximum review length is way too many steps for our RNN. Let's truncate to 200 steps. For reviews shorter than 200, we'll pad with 0s. For reviews longer than 200, we can truncate them to the first 200 characters.\n",
    "\n",
    "> **Exercise:** First, remove the review with zero length from the `reviews_ints` list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25000"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find reviews with non-zero length\n",
    "non_zero_idx = [ii for ii, review in enumerate(reviews_ints) if len(review) != 0]\n",
    "len(non_zero_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Use the non_zero_idx to filter out that review with 0 length\n",
    "reviews_ints = [reviews_ints[ii] for ii in non_zero_idx]\n",
    "labels = np.array([labels[ii] for ii in non_zero_idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Exercise:** Now, create an array `features` that contains the data we'll pass to the network. The data should come from `review_ints`, since we want to feed integers to the network. Each row should be 200 elements long. For reviews shorter than 200 words, left pad with 0s. That is, if the review is `['best', 'movie', 'ever']`, `[117, 18, 128]` as integers, the row will look like `[0, 0, 0, ..., 0, 117, 18, 128]`. For reviews longer than 200, use on the first 200 words as the feature vector.\n",
    "\n",
    "This isn't trivial and there are a bunch of ways to do this. But, if you're going to be building your own deep learning networks, you're going to have to get used to preparing your data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seq_len = 200\n",
    "# Create empty array features with 200 elements long\n",
    "features = np.zeros((len(reviews_ints), seq_len), dtype=int)\n",
    "\n",
    "# Pad the features array with reviews_ints\n",
    "for i, row in enumerate(reviews_ints):\n",
    "    features[i, -len(row):] = np.array(row)[:seq_len]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you build features correctly, it should look like that cell output below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[    0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0, 21025,   308,     6,\n",
       "            3,  1050,   207,     8,  2138,    32,     1,   171,    57,\n",
       "           15,    49,    81,  5785,    44,   382,   110,   140,    15,\n",
       "         5194,    60,   154,     9,     1,  4975,  5852,   475,    71,\n",
       "            5,   260,    12, 21025,   308,    13,  1978,     6,    74,\n",
       "         2395],\n",
       "       [    0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,    63,     4,     3,   125,\n",
       "           36,    47,  7472,  1395,    16,     3,  4181,   505,    45,\n",
       "           17],\n",
       "       [22382,    42, 46418,    15,   706, 17139,  3389,    47,    77,\n",
       "           35,  1819,    16,   154,    19,   114,     3,  1305,     5,\n",
       "          336,   147,    22,     1,   857,    12,    70,   281,  1168,\n",
       "          399,    36,   120,   283,    38,   169,     5,   382,   158,\n",
       "           42,  2269,    16,     1,   541,    90,    78,   102,     4,\n",
       "            1,  3244,    15,    43,     3,   407,  1068,   136,  8055,\n",
       "           44,   182,   140,    15,  3043,     1,   320,    22,  4818,\n",
       "        26224,   346,     5,  3090,  2092,     1, 18839, 17939,    42,\n",
       "         8055,    46,    33,   236,    29,   370,     5,   130,    56,\n",
       "           22,     1,  1928,     7,     7,    19,    48,    46,    21,\n",
       "           70,   344,     3,  2099,     5,   408,    22,     1,  1928,\n",
       "           16],\n",
       "       [ 4505,   505,    15,     3,  3342,   162,  8312,  1652,     6,\n",
       "         4819,    56,    17,  4504,  5616,   140, 11725,     5,   996,\n",
       "         4919,  2933,  4462,   566,  1201,    36,     6,  1518,    96,\n",
       "            3,   744,     4, 26225,    13,     5,    27,  3461,     9,\n",
       "        10625,     4,     8,   111,  3013,     5,     1,  1027,    15,\n",
       "            3,  4390,    82,    22,  2049,     6,  4462,   538,  2764,\n",
       "         7073, 37443,    41,   463,     1,  8312, 46419,   302,   123,\n",
       "           15,  4221,    19,  1667,   922,     1,  1652,     6,  6129,\n",
       "        19871,    34,     1,   980,  1751, 22383,   646, 24104,    27,\n",
       "          106, 11726,    13, 14045, 15097, 17940,  2457,   466, 21027,\n",
       "           36,  3266,     1,  6365,  1020,    45,    17,  2695,  2499,\n",
       "           33],\n",
       "       [    0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,   520,   119,   113,    34,\n",
       "        16372,  1816,  3737,   117,   885, 21030,   721,    10,    28,\n",
       "          124,   108,     2,   115,   137,     9,  1623,  7691,    26,\n",
       "          330,     5,   589,     1,  6130,    22,   386,     6,     3,\n",
       "          349,    15,    50,    15,   231,     9,  7473, 11399,     1,\n",
       "          191,    22,  8966,     6,    82,   880,   101,   111,  3584,\n",
       "            4],\n",
       "       [    0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           11,    20,  3637,   141,    10,   422,    23,   272,    60,\n",
       "         4355,    22,    32,    84,  3286,    22,     1,   172,     4,\n",
       "            1,   952,   507,    11,  4977,  5361,     5,   574,     4,\n",
       "         1155,    54,    53,  5304,     1,   261,    17,    41,   952,\n",
       "          125,    59,     1,   711,   137,   379,   626,    15,   111,\n",
       "         1509],\n",
       "       [    0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,    11,     6,   692,     1,    90,\n",
       "         2156,    20, 11728,     1,  2818,  5195,   249,    92,  3006,\n",
       "            8,   126,    24,   200,     3,   802,   634,     4, 22382,\n",
       "         1001],\n",
       "       [    0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,   786,   295,    10,   122,    11,     6,   419,\n",
       "            5,    29,    35,   482,    20,    19,  1281,    33,   142,\n",
       "           28,  2657,    45,  1840,    32,     1,  2778,    37,    78,\n",
       "           97,  2436,    67,  3950,    45,     2,    24,   105,   256,\n",
       "            1,   134,  1571,     2, 12399,   451,    14,   319,    11,\n",
       "           63,     6,    98,  1321,     5,   105,     1,  3767,     4,\n",
       "            3],\n",
       "       [    0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,    11,     6,\n",
       "           24,     1,   779,  3687,  2818,    20,     8,    14,    74,\n",
       "          325,  2730,    73,    90,     4,    27,    99,     2,   165,\n",
       "           68],\n",
       "       [   54,    10,    14,   116,    60,   798,   552,    71,   364,\n",
       "            5,     1,   730,     5,    66,  8057,     8,    14,    30,\n",
       "            4,   109,    99,    10,   293,    17,    60,   798,    19,\n",
       "           11,    14,     1,    64,    30,    69,  2500,    45,     4,\n",
       "          234,    93,    10,    68,   114,   108,  8057,   363,    43,\n",
       "         1009,     2,    10,    97,    28,  1431,    45,     1,   357,\n",
       "            4,    60,   110,   205,     8,    48,     3,  1929, 10880,\n",
       "            2,  2124,   354,   412,     4,    13,  6609,     2,  2974,\n",
       "         5148,  2125,  1366,     6,    30,     4,    60,   502,   876,\n",
       "           19,  8057,     6,    34,   227,     1,   247,   412,     4,\n",
       "          582,     4,    27,   599,     9,     1, 13586,   396,     4,\n",
       "        14047]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features[:10,:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training, Validation, Test\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With our data in nice shape, we'll split it into training, validation, and test sets.\n",
    "\n",
    "> **Exercise:** Create the training, validation, and test sets here. You'll need to create sets for the features and the labels, `train_x` and `train_y` for example. Define a split fraction, `split_frac` as the fraction of data to keep in the training set. Usually this is set to 0.8 or 0.9. The rest of the data will be split in half to create the validation and testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\t\tFeature Shapes:\n",
      "Train set: \t\t(20000, 200) \n",
      "Validation set: \t(2500, 200) \n",
      "Test set: \t\t(2500, 200)\n"
     ]
    }
   ],
   "source": [
    "split_frac = 0.8 # fraction of data to keep in the training set\n",
    "\n",
    "# Split the data into training and validation set\n",
    "split_idx = int(len(features) * 0.8)\n",
    "train_x, val_x = features[:split_idx], features[split_idx:]\n",
    "train_y, val_y = labels[:split_idx], labels[split_idx:]\n",
    "\n",
    "# Split half of the validation set as test set\n",
    "test_idx = int(len(val_x) * 0.5)\n",
    "val_x, test_x = val_x[:test_idx], val_x[test_idx:]\n",
    "val_y, test_y = val_y[:test_idx], val_y[test_idx:]\n",
    "\n",
    "print(\"\\t\\t\\tFeature Shapes:\")\n",
    "print(\"Train set: \\t\\t{}\".format(train_x.shape), \n",
    "      \"\\nValidation set: \\t{}\".format(val_x.shape),\n",
    "      \"\\nTest set: \\t\\t{}\".format(test_x.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With train, validation, and text fractions of 0.8, 0.1, 0.1, the final shapes should look like:\n",
    "```\n",
    "                    Feature Shapes:\n",
    "Train set: \t\t (20000, 200) \n",
    "Validation set: \t(2500, 200) \n",
    "Test set: \t\t  (2500, 200)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the graph\n",
    "\n",
    "Here, we'll build the graph. First up, defining the hyperparameters.\n",
    "\n",
    "* `lstm_size`: Number of units in the hidden layers in the LSTM cells. Usually larger is better performance wise. Common values are 128, 256, 512, etc.\n",
    "* `lstm_layers`: Number of LSTM layers in the network. I'd start with 1, then add more if I'm underfitting.\n",
    "* `batch_size`: The number of reviews to feed the network in one training pass. Typically this should be set as high as you can go without running out of memory.\n",
    "* `learning_rate`: Learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lstm_size = 256\n",
    "lstm_layers = 1\n",
    "batch_size = 128\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the network itself, we'll be passing in our 200 element long review vectors. Each batch will be `batch_size` vectors. We'll also be using dropout on the LSTM layer, so we'll make a placeholder for the keep probability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Exercise:** Create the `inputs_`, `labels_`, and drop out `keep_prob` placeholders using `tf.placeholder`.   \n",
    "`labels_` needs to be two-dimensional to work with some functions later.  Since `keep_prob` is a scalar (a 0-dimensional tensor), you shouldn't provide a size to `tf.placeholder`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_words = len(vocab_to_int) + 1 # Adding 1 because we use 0's for padding, dictionary started at 1\n",
    "\n",
    "# Create the graph object\n",
    "graph = tf.Graph()\n",
    "# Add nodes to the graph\n",
    "with graph.as_default():\n",
    "    inputs_ = tf.placeholder(tf.int32, [None, None], name = 'inputs')\n",
    "    labels_ = tf.placeholder(tf.int32, [None, None], name = 'labels')\n",
    "    keep_prob = tf.placeholder(tf.float32, name='keep_prob')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedding\n",
    "\n",
    "Now we'll add an embedding layer. We need to do this because there are 74000 words in our vocabulary. It is massively inefficient to one-hot encode our classes here. You should remember dealing with this problem from the word2vec lesson. Instead of one-hot encoding, we can have an embedding layer and use that layer as a lookup table. You could train an embedding layer using word2vec, then load it here. But, it's fine to just make a new layer and let the network learn the weights.\n",
    "\n",
    "> **Exercise:** Create the embedding lookup matrix as a `tf.Variable`. Use that embedding matrix to get the embedded vectors to pass to the LSTM cell with [`tf.nn.embedding_lookup`](https://www.tensorflow.org/api_docs/python/tf/nn/embedding_lookup). This function takes the embedding matrix and an input tensor, such as the review vectors. Then, it'll return another tensor with the embedded vectors. So, if the embedding layer has 200 units, the function will return a tensor with size [batch_size, 200].\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Size of the embedding vectors (number of units in the embedding layer)\n",
    "embed_size = 300 \n",
    "\n",
    "with graph.as_default():\n",
    "    embedding = tf.Variable(tf.random_uniform((n_words, embed_size), -1, 1))\n",
    "    embed = tf.nn.embedding_lookup(embedding, inputs_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM cell\n",
    "\n",
    "<img src=\"assets/network_diagram.png\" width=400px>\n",
    "\n",
    "Next, we'll create our LSTM cells to use in the recurrent network ([TensorFlow documentation](https://www.tensorflow.org/api_docs/python/tf/contrib/rnn)). Here we are just defining what the cells look like. This isn't actually building the graph, just defining the type of cells we want in our graph.\n",
    "\n",
    "To create a basic LSTM cell for the graph, you'll want to use `tf.contrib.rnn.BasicLSTMCell`. Looking at the function documentation:\n",
    "\n",
    "```\n",
    "tf.contrib.rnn.BasicLSTMCell(num_units, forget_bias=1.0, input_size=None, state_is_tuple=True, activation=<function tanh at 0x109f1ef28>)\n",
    "```\n",
    "\n",
    "you can see it takes a parameter called `num_units`, the number of units in the cell, called `lstm_size` in this code. So then, you can write something like \n",
    "\n",
    "```\n",
    "lstm = tf.contrib.rnn.BasicLSTMCell(num_units)\n",
    "```\n",
    "\n",
    "to create an LSTM cell with `num_units`. Next, you can add dropout to the cell with `tf.contrib.rnn.DropoutWrapper`. This just wraps the cell in another cell, but with dropout added to the inputs and/or outputs. It's a really convenient way to make your network better with almost no effort! So you'd do something like\n",
    "\n",
    "```\n",
    "drop = tf.contrib.rnn.DropoutWrapper(cell, output_keep_prob=keep_prob)\n",
    "```\n",
    "\n",
    "Most of the time, your network will have better performance with more layers. That's sort of the magic of deep learning, adding more layers allows the network to learn really complex relationships. Again, there is a simple way to create multiple layers of LSTM cells with `tf.contrib.rnn.MultiRNNCell`:\n",
    "\n",
    "```\n",
    "cell = tf.contrib.rnn.MultiRNNCell([drop] * lstm_layers)\n",
    "```\n",
    "\n",
    "Here, `[drop] * lstm_layers` creates a list of cells (`drop`) that is `lstm_layers` long. The `MultiRNNCell` wrapper builds this into multiple layers of RNN cells, one for each cell in the list.\n",
    "\n",
    "So the final cell you're using in the network is actually multiple (or just one) LSTM cells with dropout. But it all works the same from an achitectural viewpoint, just a more complicated graph in the cell.\n",
    "\n",
    "> **Exercise:** Below, use `tf.contrib.rnn.BasicLSTMCell` to create an LSTM cell. Then, add drop out to it with `tf.contrib.rnn.DropoutWrapper`. Finally, create multiple LSTM layers with `tf.contrib.rnn.MultiRNNCell`.\n",
    "\n",
    "Here is [a tutorial on building RNNs](https://www.tensorflow.org/tutorials/recurrent) that will help you out.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with graph.as_default():\n",
    "    # Your basic LSTM cell\n",
    "    lstm = tf.contrib.rnn.BasicLSTMCell(lstm_size)\n",
    "    \n",
    "    # Add dropout to the cell\n",
    "    drop = tf.contrib.rnn.DropoutWrapper(lstm, output_keep_prob=keep_prob)\n",
    "    \n",
    "    # Stack up multiple LSTM layers, for deep learning\n",
    "    cell = tf.contrib.rnn.MultiRNNCell([drop] * lstm_layers)\n",
    "    \n",
    "    # Getting an initial state of all zeros\n",
    "    initial_state = cell.zero_state(batch_size, tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN forward pass\n",
    "\n",
    "<img src=\"assets/network_diagram.png\" width=400px>\n",
    "\n",
    "Now we need to actually run the data through the RNN nodes. You can use [`tf.nn.dynamic_rnn`](https://www.tensorflow.org/api_docs/python/tf/nn/dynamic_rnn) to do this. You'd pass in the RNN cell you created (our multiple layered LSTM `cell` for instance), and the inputs to the network.\n",
    "\n",
    "```\n",
    "outputs, final_state = tf.nn.dynamic_rnn(cell, inputs, initial_state=initial_state)\n",
    "```\n",
    "\n",
    "Above I created an initial state, `initial_state`, to pass to the RNN. This is the cell state that is passed between the hidden layers in successive time steps. `tf.nn.dynamic_rnn` takes care of most of the work for us. We pass in our cell and the input to the cell, then it does the unrolling and everything else for us. It returns outputs for each time step and the final_state of the hidden layer.\n",
    "\n",
    "> **Exercise:** Use `tf.nn.dynamic_rnn` to add the forward pass through the RNN. Remember that we're actually passing in vectors from the embedding layer, `embed`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with graph.as_default():\n",
    "    outputs, final_state = tf.nn.dynamic_rnn(cell, embed,\n",
    "                                             initial_state = initial_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output\n",
    "\n",
    "We only care about the final output, we'll be using that as our sentiment prediction. So we need to grab the last output with `outputs[:, -1]`, the calculate the cost from that and `labels_`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with graph.as_default():\n",
    "    predictions = tf.contrib.layers.fully_connected(outputs[:, -1], 1, activation_fn = tf.sigmoid)\n",
    "    cost = tf.losses.mean_squared_error(labels_, predictions)\n",
    "    \n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation accuracy\n",
    "\n",
    "Here we can add a few nodes to calculate the accuracy which we'll use in the validation pass."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with graph.as_default():\n",
    "    correct_pred = tf.equal(tf.cast(tf.round(predictions), tf.int32), labels_)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batching\n",
    "\n",
    "This is a simple function for returning batches from our data. First it removes data such that we only have full batches. Then it iterates through the `x` and `y` arrays and returns slices out of those arrays with size `[batch_size]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_batches(x, y, batch_size = 100):\n",
    "    \n",
    "    n_batches = len(x)//batch_size\n",
    "    x, y = x[:n_batches * batch_size], y[:n_batches * batch_size]\n",
    "    for ii in range(0, len(x), batch_size):\n",
    "        yield x[ii:ii  +batch_size], y[ii:ii + batch_size]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "Below is the typical training code. If you want to do this yourself, feel free to delete all this code and implement it yourself. Before you run this, make sure the `checkpoints` directory exists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0/10 Iteration: 1 Train loss: 0.245\n",
      "Epoch: 0/10 Iteration: 2 Train loss: 0.247\n",
      "Epoch: 0/10 Iteration: 3 Train loss: 0.261\n",
      "Epoch: 0/10 Iteration: 4 Train loss: 0.252\n",
      "Epoch: 0/10 Iteration: 5 Train loss: 0.249\n",
      "Epoch: 0/10 Iteration: 6 Train loss: 0.251\n",
      "Epoch: 0/10 Iteration: 7 Train loss: 0.246\n",
      "Epoch: 0/10 Iteration: 8 Train loss: 0.249\n",
      "Epoch: 0/10 Iteration: 9 Train loss: 0.250\n",
      "Epoch: 0/10 Iteration: 10 Train loss: 0.262\n",
      "Epoch: 0/10 Iteration: 11 Train loss: 0.248\n",
      "Epoch: 0/10 Iteration: 12 Train loss: 0.232\n",
      "Epoch: 0/10 Iteration: 13 Train loss: 0.251\n",
      "Epoch: 0/10 Iteration: 14 Train loss: 0.231\n",
      "Epoch: 0/10 Iteration: 15 Train loss: 0.234\n",
      "Epoch: 0/10 Iteration: 16 Train loss: 0.238\n",
      "Epoch: 0/10 Iteration: 17 Train loss: 0.228\n",
      "Epoch: 0/10 Iteration: 18 Train loss: 0.222\n",
      "Epoch: 0/10 Iteration: 19 Train loss: 0.241\n",
      "Epoch: 0/10 Iteration: 20 Train loss: 0.208\n",
      "Epoch: 0/10 Iteration: 21 Train loss: 0.205\n",
      "Epoch: 0/10 Iteration: 22 Train loss: 0.201\n",
      "Epoch: 0/10 Iteration: 23 Train loss: 0.287\n",
      "Epoch: 0/10 Iteration: 24 Train loss: 0.393\n",
      "Epoch: 0/10 Iteration: 25 Train loss: 0.379\n",
      "Val acc: 0.518\n",
      "Epoch: 0/10 Iteration: 26 Train loss: 0.358\n",
      "Epoch: 0/10 Iteration: 27 Train loss: 0.307\n",
      "Epoch: 0/10 Iteration: 28 Train loss: 0.266\n",
      "Epoch: 0/10 Iteration: 29 Train loss: 0.233\n",
      "Epoch: 0/10 Iteration: 30 Train loss: 0.259\n",
      "Epoch: 0/10 Iteration: 31 Train loss: 0.245\n",
      "Epoch: 0/10 Iteration: 32 Train loss: 0.253\n",
      "Epoch: 0/10 Iteration: 33 Train loss: 0.243\n",
      "Epoch: 0/10 Iteration: 34 Train loss: 0.237\n",
      "Epoch: 0/10 Iteration: 35 Train loss: 0.240\n",
      "Epoch: 0/10 Iteration: 36 Train loss: 0.248\n",
      "Epoch: 0/10 Iteration: 37 Train loss: 0.256\n",
      "Epoch: 0/10 Iteration: 38 Train loss: 0.250\n",
      "Epoch: 0/10 Iteration: 39 Train loss: 0.269\n",
      "Epoch: 0/10 Iteration: 40 Train loss: 0.238\n",
      "Epoch: 0/10 Iteration: 41 Train loss: 0.250\n",
      "Epoch: 0/10 Iteration: 42 Train loss: 0.227\n",
      "Epoch: 0/10 Iteration: 43 Train loss: 0.240\n",
      "Epoch: 0/10 Iteration: 44 Train loss: 0.246\n",
      "Epoch: 0/10 Iteration: 45 Train loss: 0.235\n",
      "Epoch: 0/10 Iteration: 46 Train loss: 0.247\n",
      "Epoch: 0/10 Iteration: 47 Train loss: 0.243\n",
      "Epoch: 0/10 Iteration: 48 Train loss: 0.239\n",
      "Epoch: 0/10 Iteration: 49 Train loss: 0.223\n",
      "Epoch: 0/10 Iteration: 50 Train loss: 0.235\n",
      "Val acc: 0.581\n",
      "Epoch: 0/10 Iteration: 51 Train loss: 0.229\n",
      "Epoch: 0/10 Iteration: 52 Train loss: 0.225\n",
      "Epoch: 0/10 Iteration: 53 Train loss: 0.239\n",
      "Epoch: 0/10 Iteration: 54 Train loss: 0.248\n",
      "Epoch: 0/10 Iteration: 55 Train loss: 0.245\n",
      "Epoch: 0/10 Iteration: 56 Train loss: 0.252\n",
      "Epoch: 0/10 Iteration: 57 Train loss: 0.221\n",
      "Epoch: 0/10 Iteration: 58 Train loss: 0.243\n",
      "Epoch: 0/10 Iteration: 59 Train loss: 0.246\n",
      "Epoch: 0/10 Iteration: 60 Train loss: 0.217\n",
      "Epoch: 0/10 Iteration: 61 Train loss: 0.268\n",
      "Epoch: 0/10 Iteration: 62 Train loss: 0.238\n",
      "Epoch: 0/10 Iteration: 63 Train loss: 0.250\n",
      "Epoch: 0/10 Iteration: 64 Train loss: 0.249\n",
      "Epoch: 0/10 Iteration: 65 Train loss: 0.243\n",
      "Epoch: 0/10 Iteration: 66 Train loss: 0.227\n",
      "Epoch: 0/10 Iteration: 67 Train loss: 0.230\n",
      "Epoch: 0/10 Iteration: 68 Train loss: 0.249\n",
      "Epoch: 0/10 Iteration: 69 Train loss: 0.237\n",
      "Epoch: 0/10 Iteration: 70 Train loss: 0.214\n",
      "Epoch: 0/10 Iteration: 71 Train loss: 0.245\n",
      "Epoch: 0/10 Iteration: 72 Train loss: 0.228\n",
      "Epoch: 0/10 Iteration: 73 Train loss: 0.229\n",
      "Epoch: 0/10 Iteration: 74 Train loss: 0.240\n",
      "Epoch: 0/10 Iteration: 75 Train loss: 0.219\n",
      "Val acc: 0.624\n",
      "Epoch: 0/10 Iteration: 76 Train loss: 0.251\n",
      "Epoch: 0/10 Iteration: 77 Train loss: 0.223\n",
      "Epoch: 0/10 Iteration: 78 Train loss: 0.223\n",
      "Epoch: 0/10 Iteration: 79 Train loss: 0.218\n",
      "Epoch: 0/10 Iteration: 80 Train loss: 0.213\n",
      "Epoch: 0/10 Iteration: 81 Train loss: 0.232\n",
      "Epoch: 0/10 Iteration: 82 Train loss: 0.203\n",
      "Epoch: 0/10 Iteration: 83 Train loss: 0.241\n",
      "Epoch: 0/10 Iteration: 84 Train loss: 0.217\n",
      "Epoch: 0/10 Iteration: 85 Train loss: 0.222\n",
      "Epoch: 0/10 Iteration: 86 Train loss: 0.214\n",
      "Epoch: 0/10 Iteration: 87 Train loss: 0.191\n",
      "Epoch: 0/10 Iteration: 88 Train loss: 0.165\n",
      "Epoch: 0/10 Iteration: 89 Train loss: 0.219\n",
      "Epoch: 0/10 Iteration: 90 Train loss: 0.210\n",
      "Epoch: 0/10 Iteration: 91 Train loss: 0.226\n",
      "Epoch: 0/10 Iteration: 92 Train loss: 0.208\n",
      "Epoch: 0/10 Iteration: 93 Train loss: 0.240\n",
      "Epoch: 0/10 Iteration: 94 Train loss: 0.209\n",
      "Epoch: 0/10 Iteration: 95 Train loss: 0.248\n",
      "Epoch: 0/10 Iteration: 96 Train loss: 0.222\n",
      "Epoch: 0/10 Iteration: 97 Train loss: 0.200\n",
      "Epoch: 0/10 Iteration: 98 Train loss: 0.232\n",
      "Epoch: 0/10 Iteration: 99 Train loss: 0.211\n",
      "Epoch: 0/10 Iteration: 100 Train loss: 0.202\n",
      "Val acc: 0.662\n",
      "Epoch: 0/10 Iteration: 101 Train loss: 0.209\n",
      "Epoch: 0/10 Iteration: 102 Train loss: 0.240\n",
      "Epoch: 0/10 Iteration: 103 Train loss: 0.223\n",
      "Epoch: 0/10 Iteration: 104 Train loss: 0.194\n",
      "Epoch: 0/10 Iteration: 105 Train loss: 0.228\n",
      "Epoch: 0/10 Iteration: 106 Train loss: 0.192\n",
      "Epoch: 0/10 Iteration: 107 Train loss: 0.192\n",
      "Epoch: 0/10 Iteration: 108 Train loss: 0.202\n",
      "Epoch: 0/10 Iteration: 109 Train loss: 0.180\n",
      "Epoch: 0/10 Iteration: 110 Train loss: 0.182\n",
      "Epoch: 0/10 Iteration: 111 Train loss: 0.200\n",
      "Epoch: 0/10 Iteration: 112 Train loss: 0.244\n",
      "Epoch: 0/10 Iteration: 113 Train loss: 0.266\n",
      "Epoch: 0/10 Iteration: 114 Train loss: 0.230\n",
      "Epoch: 0/10 Iteration: 115 Train loss: 0.247\n",
      "Epoch: 0/10 Iteration: 116 Train loss: 0.226\n",
      "Epoch: 0/10 Iteration: 117 Train loss: 0.239\n",
      "Epoch: 0/10 Iteration: 118 Train loss: 0.245\n",
      "Epoch: 0/10 Iteration: 119 Train loss: 0.228\n",
      "Epoch: 0/10 Iteration: 120 Train loss: 0.246\n",
      "Epoch: 0/10 Iteration: 121 Train loss: 0.221\n",
      "Epoch: 0/10 Iteration: 122 Train loss: 0.199\n",
      "Epoch: 0/10 Iteration: 123 Train loss: 0.219\n",
      "Epoch: 0/10 Iteration: 124 Train loss: 0.216\n",
      "Epoch: 0/10 Iteration: 125 Train loss: 0.233\n",
      "Val acc: 0.647\n",
      "Epoch: 0/10 Iteration: 126 Train loss: 0.208\n",
      "Epoch: 0/10 Iteration: 127 Train loss: 0.206\n",
      "Epoch: 0/10 Iteration: 128 Train loss: 0.240\n",
      "Epoch: 0/10 Iteration: 129 Train loss: 0.227\n",
      "Epoch: 0/10 Iteration: 130 Train loss: 0.226\n",
      "Epoch: 0/10 Iteration: 131 Train loss: 0.229\n",
      "Epoch: 0/10 Iteration: 132 Train loss: 0.229\n",
      "Epoch: 0/10 Iteration: 133 Train loss: 0.230\n",
      "Epoch: 0/10 Iteration: 134 Train loss: 0.198\n",
      "Epoch: 0/10 Iteration: 135 Train loss: 0.222\n",
      "Epoch: 0/10 Iteration: 136 Train loss: 0.213\n",
      "Epoch: 0/10 Iteration: 137 Train loss: 0.208\n",
      "Epoch: 0/10 Iteration: 138 Train loss: 0.214\n",
      "Epoch: 0/10 Iteration: 139 Train loss: 0.234\n",
      "Epoch: 0/10 Iteration: 140 Train loss: 0.216\n",
      "Epoch: 0/10 Iteration: 141 Train loss: 0.209\n",
      "Epoch: 0/10 Iteration: 142 Train loss: 0.167\n",
      "Epoch: 0/10 Iteration: 143 Train loss: 0.199\n",
      "Epoch: 0/10 Iteration: 144 Train loss: 0.237\n",
      "Epoch: 0/10 Iteration: 145 Train loss: 0.150\n",
      "Epoch: 0/10 Iteration: 146 Train loss: 0.163\n",
      "Epoch: 0/10 Iteration: 147 Train loss: 0.167\n",
      "Epoch: 0/10 Iteration: 148 Train loss: 0.205\n",
      "Epoch: 0/10 Iteration: 149 Train loss: 0.208\n",
      "Epoch: 0/10 Iteration: 150 Train loss: 0.206\n",
      "Val acc: 0.708\n",
      "Epoch: 0/10 Iteration: 151 Train loss: 0.167\n",
      "Epoch: 0/10 Iteration: 152 Train loss: 0.235\n",
      "Epoch: 0/10 Iteration: 153 Train loss: 0.259\n",
      "Epoch: 0/10 Iteration: 154 Train loss: 0.216\n",
      "Epoch: 0/10 Iteration: 155 Train loss: 0.172\n",
      "Epoch: 0/10 Iteration: 156 Train loss: 0.210\n",
      "Epoch: 1/10 Iteration: 157 Train loss: 0.315\n",
      "Epoch: 1/10 Iteration: 158 Train loss: 0.330\n",
      "Epoch: 1/10 Iteration: 159 Train loss: 0.304\n",
      "Epoch: 1/10 Iteration: 160 Train loss: 0.282\n",
      "Epoch: 1/10 Iteration: 161 Train loss: 0.235\n",
      "Epoch: 1/10 Iteration: 162 Train loss: 0.213\n",
      "Epoch: 1/10 Iteration: 163 Train loss: 0.204\n",
      "Epoch: 1/10 Iteration: 164 Train loss: 0.219\n",
      "Epoch: 1/10 Iteration: 165 Train loss: 0.209\n",
      "Epoch: 1/10 Iteration: 166 Train loss: 0.219\n",
      "Epoch: 1/10 Iteration: 167 Train loss: 0.213\n",
      "Epoch: 1/10 Iteration: 168 Train loss: 0.216\n",
      "Epoch: 1/10 Iteration: 169 Train loss: 0.218\n",
      "Epoch: 1/10 Iteration: 170 Train loss: 0.205\n",
      "Epoch: 1/10 Iteration: 171 Train loss: 0.204\n",
      "Epoch: 1/10 Iteration: 172 Train loss: 0.202\n",
      "Epoch: 1/10 Iteration: 173 Train loss: 0.190\n",
      "Epoch: 1/10 Iteration: 174 Train loss: 0.205\n",
      "Epoch: 1/10 Iteration: 175 Train loss: 0.199\n",
      "Val acc: 0.657\n",
      "Epoch: 1/10 Iteration: 176 Train loss: 0.208\n",
      "Epoch: 1/10 Iteration: 177 Train loss: 0.197\n",
      "Epoch: 1/10 Iteration: 178 Train loss: 0.188\n",
      "Epoch: 1/10 Iteration: 179 Train loss: 0.212\n",
      "Epoch: 1/10 Iteration: 180 Train loss: 0.192\n",
      "Epoch: 1/10 Iteration: 181 Train loss: 0.192\n",
      "Epoch: 1/10 Iteration: 182 Train loss: 0.224\n",
      "Epoch: 1/10 Iteration: 183 Train loss: 0.180\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10 Iteration: 184 Train loss: 0.199\n",
      "Epoch: 1/10 Iteration: 185 Train loss: 0.183\n",
      "Epoch: 1/10 Iteration: 186 Train loss: 0.217\n",
      "Epoch: 1/10 Iteration: 187 Train loss: 0.232\n",
      "Epoch: 1/10 Iteration: 188 Train loss: 0.248\n",
      "Epoch: 1/10 Iteration: 189 Train loss: 0.214\n",
      "Epoch: 1/10 Iteration: 190 Train loss: 0.229\n",
      "Epoch: 1/10 Iteration: 191 Train loss: 0.239\n",
      "Epoch: 1/10 Iteration: 192 Train loss: 0.221\n",
      "Epoch: 1/10 Iteration: 193 Train loss: 0.230\n",
      "Epoch: 1/10 Iteration: 194 Train loss: 0.238\n",
      "Epoch: 1/10 Iteration: 195 Train loss: 0.247\n",
      "Epoch: 1/10 Iteration: 196 Train loss: 0.217\n",
      "Epoch: 1/10 Iteration: 197 Train loss: 0.213\n",
      "Epoch: 1/10 Iteration: 198 Train loss: 0.188\n",
      "Epoch: 1/10 Iteration: 199 Train loss: 0.213\n",
      "Epoch: 1/10 Iteration: 200 Train loss: 0.218\n",
      "Val acc: 0.627\n",
      "Epoch: 1/10 Iteration: 201 Train loss: 0.229\n",
      "Epoch: 1/10 Iteration: 202 Train loss: 0.218\n",
      "Epoch: 1/10 Iteration: 203 Train loss: 0.231\n",
      "Epoch: 1/10 Iteration: 204 Train loss: 0.216\n",
      "Epoch: 1/10 Iteration: 205 Train loss: 0.194\n",
      "Epoch: 1/10 Iteration: 206 Train loss: 0.205\n",
      "Epoch: 1/10 Iteration: 207 Train loss: 0.193\n",
      "Epoch: 1/10 Iteration: 208 Train loss: 0.201\n",
      "Epoch: 1/10 Iteration: 209 Train loss: 0.219\n",
      "Epoch: 1/10 Iteration: 210 Train loss: 0.221\n",
      "Epoch: 1/10 Iteration: 211 Train loss: 0.202\n",
      "Epoch: 1/10 Iteration: 212 Train loss: 0.232\n",
      "Epoch: 1/10 Iteration: 213 Train loss: 0.189\n",
      "Epoch: 1/10 Iteration: 214 Train loss: 0.214\n",
      "Epoch: 1/10 Iteration: 215 Train loss: 0.218\n",
      "Epoch: 1/10 Iteration: 216 Train loss: 0.187\n",
      "Epoch: 1/10 Iteration: 217 Train loss: 0.235\n",
      "Epoch: 1/10 Iteration: 218 Train loss: 0.200\n",
      "Epoch: 1/10 Iteration: 219 Train loss: 0.211\n",
      "Epoch: 1/10 Iteration: 220 Train loss: 0.217\n",
      "Epoch: 1/10 Iteration: 221 Train loss: 0.216\n",
      "Epoch: 1/10 Iteration: 222 Train loss: 0.180\n",
      "Epoch: 1/10 Iteration: 223 Train loss: 0.201\n",
      "Epoch: 1/10 Iteration: 224 Train loss: 0.204\n",
      "Epoch: 1/10 Iteration: 225 Train loss: 0.199\n",
      "Val acc: 0.661\n",
      "Epoch: 1/10 Iteration: 226 Train loss: 0.156\n",
      "Epoch: 1/10 Iteration: 227 Train loss: 0.197\n",
      "Epoch: 1/10 Iteration: 228 Train loss: 0.172\n",
      "Epoch: 1/10 Iteration: 229 Train loss: 0.174\n",
      "Epoch: 1/10 Iteration: 230 Train loss: 0.206\n",
      "Epoch: 1/10 Iteration: 231 Train loss: 0.173\n",
      "Epoch: 1/10 Iteration: 232 Train loss: 0.194\n",
      "Epoch: 1/10 Iteration: 233 Train loss: 0.171\n",
      "Epoch: 1/10 Iteration: 234 Train loss: 0.174\n",
      "Epoch: 1/10 Iteration: 235 Train loss: 0.152\n",
      "Epoch: 1/10 Iteration: 236 Train loss: 0.134\n",
      "Epoch: 1/10 Iteration: 237 Train loss: 0.167\n",
      "Epoch: 1/10 Iteration: 238 Train loss: 0.130\n",
      "Epoch: 1/10 Iteration: 239 Train loss: 0.159\n",
      "Epoch: 1/10 Iteration: 240 Train loss: 0.123\n",
      "Epoch: 1/10 Iteration: 241 Train loss: 0.126\n",
      "Epoch: 1/10 Iteration: 242 Train loss: 0.183\n",
      "Epoch: 1/10 Iteration: 243 Train loss: 0.189\n",
      "Epoch: 1/10 Iteration: 244 Train loss: 0.147\n",
      "Epoch: 1/10 Iteration: 245 Train loss: 0.213\n",
      "Epoch: 1/10 Iteration: 246 Train loss: 0.237\n",
      "Epoch: 1/10 Iteration: 247 Train loss: 0.289\n",
      "Epoch: 1/10 Iteration: 248 Train loss: 0.360\n",
      "Epoch: 1/10 Iteration: 249 Train loss: 0.359\n",
      "Epoch: 1/10 Iteration: 250 Train loss: 0.365\n",
      "Val acc: 0.619\n",
      "Epoch: 1/10 Iteration: 251 Train loss: 0.370\n",
      "Epoch: 1/10 Iteration: 252 Train loss: 0.279\n",
      "Epoch: 1/10 Iteration: 253 Train loss: 0.259\n",
      "Epoch: 1/10 Iteration: 254 Train loss: 0.225\n",
      "Epoch: 1/10 Iteration: 255 Train loss: 0.242\n",
      "Epoch: 1/10 Iteration: 256 Train loss: 0.205\n",
      "Epoch: 1/10 Iteration: 257 Train loss: 0.216\n",
      "Epoch: 1/10 Iteration: 258 Train loss: 0.237\n",
      "Epoch: 1/10 Iteration: 259 Train loss: 0.231\n",
      "Epoch: 1/10 Iteration: 260 Train loss: 0.234\n",
      "Epoch: 1/10 Iteration: 261 Train loss: 0.230\n",
      "Epoch: 1/10 Iteration: 262 Train loss: 0.254\n",
      "Epoch: 1/10 Iteration: 263 Train loss: 0.287\n",
      "Epoch: 1/10 Iteration: 264 Train loss: 0.281\n",
      "Epoch: 1/10 Iteration: 265 Train loss: 0.243\n",
      "Epoch: 1/10 Iteration: 266 Train loss: 0.238\n",
      "Epoch: 1/10 Iteration: 267 Train loss: 0.236\n",
      "Epoch: 1/10 Iteration: 268 Train loss: 0.219\n",
      "Epoch: 1/10 Iteration: 269 Train loss: 0.268\n",
      "Epoch: 1/10 Iteration: 270 Train loss: 0.244\n",
      "Epoch: 1/10 Iteration: 271 Train loss: 0.255\n",
      "Epoch: 1/10 Iteration: 272 Train loss: 0.244\n",
      "Epoch: 1/10 Iteration: 273 Train loss: 0.260\n",
      "Epoch: 1/10 Iteration: 274 Train loss: 0.235\n",
      "Epoch: 1/10 Iteration: 275 Train loss: 0.251\n",
      "Val acc: 0.542\n",
      "Epoch: 1/10 Iteration: 276 Train loss: 0.258\n",
      "Epoch: 1/10 Iteration: 277 Train loss: 0.251\n",
      "Epoch: 1/10 Iteration: 278 Train loss: 0.232\n",
      "Epoch: 1/10 Iteration: 279 Train loss: 0.274\n",
      "Epoch: 1/10 Iteration: 280 Train loss: 0.250\n",
      "Epoch: 1/10 Iteration: 281 Train loss: 0.244\n",
      "Epoch: 1/10 Iteration: 282 Train loss: 0.230\n",
      "Epoch: 1/10 Iteration: 283 Train loss: 0.231\n",
      "Epoch: 1/10 Iteration: 284 Train loss: 0.235\n",
      "Epoch: 1/10 Iteration: 285 Train loss: 0.243\n",
      "Epoch: 1/10 Iteration: 286 Train loss: 0.237\n",
      "Epoch: 1/10 Iteration: 287 Train loss: 0.228\n",
      "Epoch: 1/10 Iteration: 288 Train loss: 0.241\n",
      "Epoch: 1/10 Iteration: 289 Train loss: 0.245\n",
      "Epoch: 1/10 Iteration: 290 Train loss: 0.220\n",
      "Epoch: 1/10 Iteration: 291 Train loss: 0.231\n",
      "Epoch: 1/10 Iteration: 292 Train loss: 0.216\n",
      "Epoch: 1/10 Iteration: 293 Train loss: 0.224\n",
      "Epoch: 1/10 Iteration: 294 Train loss: 0.245\n",
      "Epoch: 1/10 Iteration: 295 Train loss: 0.241\n",
      "Epoch: 1/10 Iteration: 296 Train loss: 0.230\n",
      "Epoch: 1/10 Iteration: 297 Train loss: 0.234\n",
      "Epoch: 1/10 Iteration: 298 Train loss: 0.201\n",
      "Epoch: 1/10 Iteration: 299 Train loss: 0.211\n",
      "Epoch: 1/10 Iteration: 300 Train loss: 0.207\n",
      "Val acc: 0.618\n",
      "Epoch: 1/10 Iteration: 301 Train loss: 0.205\n",
      "Epoch: 1/10 Iteration: 302 Train loss: 0.198\n",
      "Epoch: 1/10 Iteration: 303 Train loss: 0.229\n",
      "Epoch: 1/10 Iteration: 304 Train loss: 0.210\n",
      "Epoch: 1/10 Iteration: 305 Train loss: 0.182\n",
      "Epoch: 1/10 Iteration: 306 Train loss: 0.196\n",
      "Epoch: 1/10 Iteration: 307 Train loss: 0.189\n",
      "Epoch: 1/10 Iteration: 308 Train loss: 0.219\n",
      "Epoch: 1/10 Iteration: 309 Train loss: 0.226\n",
      "Epoch: 1/10 Iteration: 310 Train loss: 0.239\n",
      "Epoch: 1/10 Iteration: 311 Train loss: 0.210\n",
      "Epoch: 1/10 Iteration: 312 Train loss: 0.225\n",
      "Epoch: 2/10 Iteration: 313 Train loss: 0.219\n",
      "Epoch: 2/10 Iteration: 314 Train loss: 0.225\n",
      "Epoch: 2/10 Iteration: 315 Train loss: 0.188\n",
      "Epoch: 2/10 Iteration: 316 Train loss: 0.219\n",
      "Epoch: 2/10 Iteration: 317 Train loss: 0.184\n",
      "Epoch: 2/10 Iteration: 318 Train loss: 0.182\n",
      "Epoch: 2/10 Iteration: 319 Train loss: 0.221\n",
      "Epoch: 2/10 Iteration: 320 Train loss: 0.192\n",
      "Epoch: 2/10 Iteration: 321 Train loss: 0.154\n",
      "Epoch: 2/10 Iteration: 322 Train loss: 0.200\n",
      "Epoch: 2/10 Iteration: 323 Train loss: 0.183\n",
      "Epoch: 2/10 Iteration: 324 Train loss: 0.197\n",
      "Epoch: 2/10 Iteration: 325 Train loss: 0.173\n",
      "Val acc: 0.707\n",
      "Epoch: 2/10 Iteration: 326 Train loss: 0.180\n",
      "Epoch: 2/10 Iteration: 327 Train loss: 0.169\n",
      "Epoch: 2/10 Iteration: 328 Train loss: 0.192\n",
      "Epoch: 2/10 Iteration: 329 Train loss: 0.196\n",
      "Epoch: 2/10 Iteration: 330 Train loss: 0.189\n",
      "Epoch: 2/10 Iteration: 331 Train loss: 0.200\n",
      "Epoch: 2/10 Iteration: 332 Train loss: 0.188\n",
      "Epoch: 2/10 Iteration: 333 Train loss: 0.192\n",
      "Epoch: 2/10 Iteration: 334 Train loss: 0.166\n",
      "Epoch: 2/10 Iteration: 335 Train loss: 0.222\n",
      "Epoch: 2/10 Iteration: 336 Train loss: 0.210\n",
      "Epoch: 2/10 Iteration: 337 Train loss: 0.212\n",
      "Epoch: 2/10 Iteration: 338 Train loss: 0.224\n",
      "Epoch: 2/10 Iteration: 339 Train loss: 0.210\n",
      "Epoch: 2/10 Iteration: 340 Train loss: 0.185\n",
      "Epoch: 2/10 Iteration: 341 Train loss: 0.208\n",
      "Epoch: 2/10 Iteration: 342 Train loss: 0.224\n",
      "Epoch: 2/10 Iteration: 343 Train loss: 0.195\n",
      "Epoch: 2/10 Iteration: 344 Train loss: 0.217\n",
      "Epoch: 2/10 Iteration: 345 Train loss: 0.188\n",
      "Epoch: 2/10 Iteration: 346 Train loss: 0.187\n",
      "Epoch: 2/10 Iteration: 347 Train loss: 0.189\n",
      "Epoch: 2/10 Iteration: 348 Train loss: 0.191\n",
      "Epoch: 2/10 Iteration: 349 Train loss: 0.191\n",
      "Epoch: 2/10 Iteration: 350 Train loss: 0.207\n",
      "Val acc: 0.692\n",
      "Epoch: 2/10 Iteration: 351 Train loss: 0.204\n",
      "Epoch: 2/10 Iteration: 352 Train loss: 0.172\n",
      "Epoch: 2/10 Iteration: 353 Train loss: 0.164\n",
      "Epoch: 2/10 Iteration: 354 Train loss: 0.141\n",
      "Epoch: 2/10 Iteration: 355 Train loss: 0.203\n",
      "Epoch: 2/10 Iteration: 356 Train loss: 0.194\n",
      "Epoch: 2/10 Iteration: 357 Train loss: 0.183\n",
      "Epoch: 2/10 Iteration: 358 Train loss: 0.212\n",
      "Epoch: 2/10 Iteration: 359 Train loss: 0.229\n",
      "Epoch: 2/10 Iteration: 360 Train loss: 0.178\n",
      "Epoch: 2/10 Iteration: 361 Train loss: 0.137\n",
      "Epoch: 2/10 Iteration: 362 Train loss: 0.174\n",
      "Epoch: 2/10 Iteration: 363 Train loss: 0.156\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2/10 Iteration: 364 Train loss: 0.140\n",
      "Epoch: 2/10 Iteration: 365 Train loss: 0.181\n",
      "Epoch: 2/10 Iteration: 366 Train loss: 0.167\n",
      "Epoch: 2/10 Iteration: 367 Train loss: 0.131\n",
      "Epoch: 2/10 Iteration: 368 Train loss: 0.195\n",
      "Epoch: 2/10 Iteration: 369 Train loss: 0.157\n",
      "Epoch: 2/10 Iteration: 370 Train loss: 0.204\n",
      "Epoch: 2/10 Iteration: 371 Train loss: 0.157\n",
      "Epoch: 2/10 Iteration: 372 Train loss: 0.165\n",
      "Epoch: 2/10 Iteration: 373 Train loss: 0.194\n",
      "Epoch: 2/10 Iteration: 374 Train loss: 0.140\n",
      "Epoch: 2/10 Iteration: 375 Train loss: 0.182\n",
      "Val acc: 0.660\n",
      "Epoch: 2/10 Iteration: 376 Train loss: 0.252\n",
      "Epoch: 2/10 Iteration: 377 Train loss: 0.314\n",
      "Epoch: 2/10 Iteration: 378 Train loss: 0.337\n",
      "Epoch: 2/10 Iteration: 379 Train loss: 0.327\n",
      "Epoch: 2/10 Iteration: 380 Train loss: 0.345\n",
      "Epoch: 2/10 Iteration: 381 Train loss: 0.321\n",
      "Epoch: 2/10 Iteration: 382 Train loss: 0.283\n",
      "Epoch: 2/10 Iteration: 383 Train loss: 0.274\n",
      "Epoch: 2/10 Iteration: 384 Train loss: 0.246\n",
      "Epoch: 2/10 Iteration: 385 Train loss: 0.239\n",
      "Epoch: 2/10 Iteration: 386 Train loss: 0.256\n",
      "Epoch: 2/10 Iteration: 387 Train loss: 0.216\n",
      "Epoch: 2/10 Iteration: 388 Train loss: 0.210\n",
      "Epoch: 2/10 Iteration: 389 Train loss: 0.242\n",
      "Epoch: 2/10 Iteration: 390 Train loss: 0.211\n",
      "Epoch: 2/10 Iteration: 391 Train loss: 0.238\n",
      "Epoch: 2/10 Iteration: 392 Train loss: 0.231\n",
      "Epoch: 2/10 Iteration: 393 Train loss: 0.235\n",
      "Epoch: 2/10 Iteration: 394 Train loss: 0.239\n",
      "Epoch: 2/10 Iteration: 395 Train loss: 0.243\n",
      "Epoch: 2/10 Iteration: 396 Train loss: 0.212\n",
      "Epoch: 2/10 Iteration: 397 Train loss: 0.229\n",
      "Epoch: 2/10 Iteration: 398 Train loss: 0.227\n",
      "Epoch: 2/10 Iteration: 399 Train loss: 0.209\n",
      "Epoch: 2/10 Iteration: 400 Train loss: 0.169\n",
      "Val acc: 0.685\n",
      "Epoch: 2/10 Iteration: 401 Train loss: 0.192\n",
      "Epoch: 2/10 Iteration: 402 Train loss: 0.162\n",
      "Epoch: 2/10 Iteration: 403 Train loss: 0.171\n",
      "Epoch: 2/10 Iteration: 404 Train loss: 0.194\n",
      "Epoch: 2/10 Iteration: 405 Train loss: 0.180\n",
      "Epoch: 2/10 Iteration: 406 Train loss: 0.160\n",
      "Epoch: 2/10 Iteration: 407 Train loss: 0.212\n",
      "Epoch: 2/10 Iteration: 408 Train loss: 0.163\n",
      "Epoch: 2/10 Iteration: 409 Train loss: 0.156\n",
      "Epoch: 2/10 Iteration: 410 Train loss: 0.174\n",
      "Epoch: 2/10 Iteration: 411 Train loss: 0.171\n",
      "Epoch: 2/10 Iteration: 412 Train loss: 0.180\n",
      "Epoch: 2/10 Iteration: 413 Train loss: 0.196\n",
      "Epoch: 2/10 Iteration: 414 Train loss: 0.193\n",
      "Epoch: 2/10 Iteration: 415 Train loss: 0.199\n",
      "Epoch: 2/10 Iteration: 416 Train loss: 0.183\n",
      "Epoch: 2/10 Iteration: 417 Train loss: 0.189\n",
      "Epoch: 2/10 Iteration: 418 Train loss: 0.183\n",
      "Epoch: 2/10 Iteration: 419 Train loss: 0.165\n",
      "Epoch: 2/10 Iteration: 420 Train loss: 0.194\n",
      "Epoch: 2/10 Iteration: 421 Train loss: 0.164\n",
      "Epoch: 2/10 Iteration: 422 Train loss: 0.146\n",
      "Epoch: 2/10 Iteration: 423 Train loss: 0.153\n",
      "Epoch: 2/10 Iteration: 424 Train loss: 0.202\n",
      "Epoch: 2/10 Iteration: 425 Train loss: 0.220\n",
      "Val acc: 0.712\n",
      "Epoch: 2/10 Iteration: 426 Train loss: 0.163\n",
      "Epoch: 2/10 Iteration: 427 Train loss: 0.206\n",
      "Epoch: 2/10 Iteration: 428 Train loss: 0.198\n",
      "Epoch: 2/10 Iteration: 429 Train loss: 0.206\n",
      "Epoch: 2/10 Iteration: 430 Train loss: 0.218\n",
      "Epoch: 2/10 Iteration: 431 Train loss: 0.213\n",
      "Epoch: 2/10 Iteration: 432 Train loss: 0.210\n",
      "Epoch: 2/10 Iteration: 433 Train loss: 0.187\n",
      "Epoch: 2/10 Iteration: 434 Train loss: 0.181\n",
      "Epoch: 2/10 Iteration: 435 Train loss: 0.192\n",
      "Epoch: 2/10 Iteration: 436 Train loss: 0.176\n",
      "Epoch: 2/10 Iteration: 437 Train loss: 0.200\n",
      "Epoch: 2/10 Iteration: 438 Train loss: 0.188\n",
      "Epoch: 2/10 Iteration: 439 Train loss: 0.178\n",
      "Epoch: 2/10 Iteration: 440 Train loss: 0.201\n",
      "Epoch: 2/10 Iteration: 441 Train loss: 0.182\n",
      "Epoch: 2/10 Iteration: 442 Train loss: 0.181\n",
      "Epoch: 2/10 Iteration: 443 Train loss: 0.211\n",
      "Epoch: 2/10 Iteration: 444 Train loss: 0.198\n",
      "Epoch: 2/10 Iteration: 445 Train loss: 0.173\n",
      "Epoch: 2/10 Iteration: 446 Train loss: 0.145\n",
      "Epoch: 2/10 Iteration: 447 Train loss: 0.179\n",
      "Epoch: 2/10 Iteration: 448 Train loss: 0.174\n",
      "Epoch: 2/10 Iteration: 449 Train loss: 0.173\n",
      "Epoch: 2/10 Iteration: 450 Train loss: 0.184\n",
      "Val acc: 0.710\n",
      "Epoch: 2/10 Iteration: 451 Train loss: 0.180\n",
      "Epoch: 2/10 Iteration: 452 Train loss: 0.171\n",
      "Epoch: 2/10 Iteration: 453 Train loss: 0.154\n",
      "Epoch: 2/10 Iteration: 454 Train loss: 0.129\n",
      "Epoch: 2/10 Iteration: 455 Train loss: 0.112\n",
      "Epoch: 2/10 Iteration: 456 Train loss: 0.170\n",
      "Epoch: 2/10 Iteration: 457 Train loss: 0.103\n",
      "Epoch: 2/10 Iteration: 458 Train loss: 0.098\n",
      "Epoch: 2/10 Iteration: 459 Train loss: 0.132\n",
      "Epoch: 2/10 Iteration: 460 Train loss: 0.146\n",
      "Epoch: 2/10 Iteration: 461 Train loss: 0.111\n",
      "Epoch: 2/10 Iteration: 462 Train loss: 0.136\n",
      "Epoch: 2/10 Iteration: 463 Train loss: 0.100\n",
      "Epoch: 2/10 Iteration: 464 Train loss: 0.168\n",
      "Epoch: 2/10 Iteration: 465 Train loss: 0.199\n",
      "Epoch: 2/10 Iteration: 466 Train loss: 0.141\n",
      "Epoch: 2/10 Iteration: 467 Train loss: 0.165\n",
      "Epoch: 2/10 Iteration: 468 Train loss: 0.161\n",
      "Epoch: 3/10 Iteration: 469 Train loss: 0.204\n",
      "Epoch: 3/10 Iteration: 470 Train loss: 0.113\n",
      "Epoch: 3/10 Iteration: 471 Train loss: 0.107\n",
      "Epoch: 3/10 Iteration: 472 Train loss: 0.160\n",
      "Epoch: 3/10 Iteration: 473 Train loss: 0.165\n",
      "Epoch: 3/10 Iteration: 474 Train loss: 0.139\n",
      "Epoch: 3/10 Iteration: 475 Train loss: 0.139\n",
      "Val acc: 0.767\n",
      "Epoch: 3/10 Iteration: 476 Train loss: 0.123\n",
      "Epoch: 3/10 Iteration: 477 Train loss: 0.133\n",
      "Epoch: 3/10 Iteration: 478 Train loss: 0.164\n",
      "Epoch: 3/10 Iteration: 479 Train loss: 0.138\n",
      "Epoch: 3/10 Iteration: 480 Train loss: 0.148\n",
      "Epoch: 3/10 Iteration: 481 Train loss: 0.149\n",
      "Epoch: 3/10 Iteration: 482 Train loss: 0.134\n",
      "Epoch: 3/10 Iteration: 483 Train loss: 0.141\n",
      "Epoch: 3/10 Iteration: 484 Train loss: 0.140\n",
      "Epoch: 3/10 Iteration: 485 Train loss: 0.096\n",
      "Epoch: 3/10 Iteration: 486 Train loss: 0.166\n",
      "Epoch: 3/10 Iteration: 487 Train loss: 0.165\n",
      "Epoch: 3/10 Iteration: 488 Train loss: 0.122\n",
      "Epoch: 3/10 Iteration: 489 Train loss: 0.157\n",
      "Epoch: 3/10 Iteration: 490 Train loss: 0.141\n",
      "Epoch: 3/10 Iteration: 491 Train loss: 0.170\n",
      "Epoch: 3/10 Iteration: 492 Train loss: 0.196\n",
      "Epoch: 3/10 Iteration: 493 Train loss: 0.176\n",
      "Epoch: 3/10 Iteration: 494 Train loss: 0.168\n",
      "Epoch: 3/10 Iteration: 495 Train loss: 0.151\n",
      "Epoch: 3/10 Iteration: 496 Train loss: 0.103\n",
      "Epoch: 3/10 Iteration: 497 Train loss: 0.202\n",
      "Epoch: 3/10 Iteration: 498 Train loss: 0.147\n",
      "Epoch: 3/10 Iteration: 499 Train loss: 0.194\n",
      "Epoch: 3/10 Iteration: 500 Train loss: 0.203\n",
      "Val acc: 0.759\n",
      "Epoch: 3/10 Iteration: 501 Train loss: 0.156\n",
      "Epoch: 3/10 Iteration: 502 Train loss: 0.152\n",
      "Epoch: 3/10 Iteration: 503 Train loss: 0.150\n",
      "Epoch: 3/10 Iteration: 504 Train loss: 0.173\n",
      "Epoch: 3/10 Iteration: 505 Train loss: 0.175\n",
      "Epoch: 3/10 Iteration: 506 Train loss: 0.169\n",
      "Epoch: 3/10 Iteration: 507 Train loss: 0.180\n",
      "Epoch: 3/10 Iteration: 508 Train loss: 0.169\n",
      "Epoch: 3/10 Iteration: 509 Train loss: 0.208\n",
      "Epoch: 3/10 Iteration: 510 Train loss: 0.160\n",
      "Epoch: 3/10 Iteration: 511 Train loss: 0.175\n",
      "Epoch: 3/10 Iteration: 512 Train loss: 0.165\n",
      "Epoch: 3/10 Iteration: 513 Train loss: 0.184\n",
      "Epoch: 3/10 Iteration: 514 Train loss: 0.173\n",
      "Epoch: 3/10 Iteration: 515 Train loss: 0.194\n",
      "Epoch: 3/10 Iteration: 516 Train loss: 0.167\n",
      "Epoch: 3/10 Iteration: 517 Train loss: 0.145\n",
      "Epoch: 3/10 Iteration: 518 Train loss: 0.145\n",
      "Epoch: 3/10 Iteration: 519 Train loss: 0.167\n",
      "Epoch: 3/10 Iteration: 520 Train loss: 0.180\n",
      "Epoch: 3/10 Iteration: 521 Train loss: 0.224\n",
      "Epoch: 3/10 Iteration: 522 Train loss: 0.199\n",
      "Epoch: 3/10 Iteration: 523 Train loss: 0.179\n",
      "Epoch: 3/10 Iteration: 524 Train loss: 0.228\n",
      "Epoch: 3/10 Iteration: 525 Train loss: 0.189\n",
      "Val acc: 0.641\n",
      "Epoch: 3/10 Iteration: 526 Train loss: 0.205\n",
      "Epoch: 3/10 Iteration: 527 Train loss: 0.189\n",
      "Epoch: 3/10 Iteration: 528 Train loss: 0.182\n",
      "Epoch: 3/10 Iteration: 529 Train loss: 0.221\n",
      "Epoch: 3/10 Iteration: 530 Train loss: 0.179\n",
      "Epoch: 3/10 Iteration: 531 Train loss: 0.206\n",
      "Epoch: 3/10 Iteration: 532 Train loss: 0.193\n",
      "Epoch: 3/10 Iteration: 533 Train loss: 0.203\n",
      "Epoch: 3/10 Iteration: 534 Train loss: 0.186\n",
      "Epoch: 3/10 Iteration: 535 Train loss: 0.188\n",
      "Epoch: 3/10 Iteration: 536 Train loss: 0.183\n",
      "Epoch: 3/10 Iteration: 537 Train loss: 0.173\n",
      "Epoch: 3/10 Iteration: 538 Train loss: 0.162\n",
      "Epoch: 3/10 Iteration: 539 Train loss: 0.168\n",
      "Epoch: 3/10 Iteration: 540 Train loss: 0.157\n",
      "Epoch: 3/10 Iteration: 541 Train loss: 0.156\n",
      "Epoch: 3/10 Iteration: 542 Train loss: 0.173\n",
      "Epoch: 3/10 Iteration: 543 Train loss: 0.148\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3/10 Iteration: 544 Train loss: 0.146\n",
      "Epoch: 3/10 Iteration: 545 Train loss: 0.164\n",
      "Epoch: 3/10 Iteration: 546 Train loss: 0.134\n",
      "Epoch: 3/10 Iteration: 547 Train loss: 0.133\n",
      "Epoch: 3/10 Iteration: 548 Train loss: 0.142\n",
      "Epoch: 3/10 Iteration: 549 Train loss: 0.221\n",
      "Epoch: 3/10 Iteration: 550 Train loss: 0.144\n",
      "Val acc: 0.723\n",
      "Epoch: 3/10 Iteration: 551 Train loss: 0.157\n",
      "Epoch: 3/10 Iteration: 552 Train loss: 0.197\n",
      "Epoch: 3/10 Iteration: 553 Train loss: 0.217\n",
      "Epoch: 3/10 Iteration: 554 Train loss: 0.185\n",
      "Epoch: 3/10 Iteration: 555 Train loss: 0.139\n",
      "Epoch: 3/10 Iteration: 556 Train loss: 0.114\n",
      "Epoch: 3/10 Iteration: 557 Train loss: 0.156\n",
      "Epoch: 3/10 Iteration: 558 Train loss: 0.114\n",
      "Epoch: 3/10 Iteration: 559 Train loss: 0.133\n",
      "Epoch: 3/10 Iteration: 560 Train loss: 0.183\n",
      "Epoch: 3/10 Iteration: 561 Train loss: 0.190\n",
      "Epoch: 3/10 Iteration: 562 Train loss: 0.144\n",
      "Epoch: 3/10 Iteration: 563 Train loss: 0.180\n",
      "Epoch: 3/10 Iteration: 564 Train loss: 0.124\n",
      "Epoch: 3/10 Iteration: 565 Train loss: 0.131\n",
      "Epoch: 3/10 Iteration: 566 Train loss: 0.117\n",
      "Epoch: 3/10 Iteration: 567 Train loss: 0.175\n",
      "Epoch: 3/10 Iteration: 568 Train loss: 0.117\n",
      "Epoch: 3/10 Iteration: 569 Train loss: 0.162\n",
      "Epoch: 3/10 Iteration: 570 Train loss: 0.138\n",
      "Epoch: 3/10 Iteration: 571 Train loss: 0.155\n",
      "Epoch: 3/10 Iteration: 572 Train loss: 0.128\n",
      "Epoch: 3/10 Iteration: 573 Train loss: 0.145\n",
      "Epoch: 3/10 Iteration: 574 Train loss: 0.145\n",
      "Epoch: 3/10 Iteration: 575 Train loss: 0.160\n",
      "Val acc: 0.747\n",
      "Epoch: 3/10 Iteration: 576 Train loss: 0.155\n",
      "Epoch: 3/10 Iteration: 577 Train loss: 0.127\n",
      "Epoch: 3/10 Iteration: 578 Train loss: 0.157\n",
      "Epoch: 3/10 Iteration: 579 Train loss: 0.134\n",
      "Epoch: 3/10 Iteration: 580 Train loss: 0.159\n",
      "Epoch: 3/10 Iteration: 581 Train loss: 0.192\n",
      "Epoch: 3/10 Iteration: 582 Train loss: 0.145\n",
      "Epoch: 3/10 Iteration: 583 Train loss: 0.153\n",
      "Epoch: 3/10 Iteration: 584 Train loss: 0.142\n",
      "Epoch: 3/10 Iteration: 585 Train loss: 0.138\n",
      "Epoch: 3/10 Iteration: 586 Train loss: 0.169\n",
      "Epoch: 3/10 Iteration: 587 Train loss: 0.149\n",
      "Epoch: 3/10 Iteration: 588 Train loss: 0.136\n",
      "Epoch: 3/10 Iteration: 589 Train loss: 0.119\n",
      "Epoch: 3/10 Iteration: 590 Train loss: 0.106\n",
      "Epoch: 3/10 Iteration: 591 Train loss: 0.141\n",
      "Epoch: 3/10 Iteration: 592 Train loss: 0.141\n",
      "Epoch: 3/10 Iteration: 593 Train loss: 0.160\n",
      "Epoch: 3/10 Iteration: 594 Train loss: 0.146\n",
      "Epoch: 3/10 Iteration: 595 Train loss: 0.131\n",
      "Epoch: 3/10 Iteration: 596 Train loss: 0.128\n",
      "Epoch: 3/10 Iteration: 597 Train loss: 0.130\n",
      "Epoch: 3/10 Iteration: 598 Train loss: 0.113\n",
      "Epoch: 3/10 Iteration: 599 Train loss: 0.121\n",
      "Epoch: 3/10 Iteration: 600 Train loss: 0.161\n",
      "Val acc: 0.785\n",
      "Epoch: 3/10 Iteration: 601 Train loss: 0.158\n",
      "Epoch: 3/10 Iteration: 602 Train loss: 0.101\n",
      "Epoch: 3/10 Iteration: 603 Train loss: 0.125\n",
      "Epoch: 3/10 Iteration: 604 Train loss: 0.113\n",
      "Epoch: 3/10 Iteration: 605 Train loss: 0.102\n",
      "Epoch: 3/10 Iteration: 606 Train loss: 0.113\n",
      "Epoch: 3/10 Iteration: 607 Train loss: 0.135\n",
      "Epoch: 3/10 Iteration: 608 Train loss: 0.114\n",
      "Epoch: 3/10 Iteration: 609 Train loss: 0.099\n",
      "Epoch: 3/10 Iteration: 610 Train loss: 0.070\n",
      "Epoch: 3/10 Iteration: 611 Train loss: 0.083\n",
      "Epoch: 3/10 Iteration: 612 Train loss: 0.125\n",
      "Epoch: 3/10 Iteration: 613 Train loss: 0.079\n",
      "Epoch: 3/10 Iteration: 614 Train loss: 0.074\n",
      "Epoch: 3/10 Iteration: 615 Train loss: 0.074\n",
      "Epoch: 3/10 Iteration: 616 Train loss: 0.110\n",
      "Epoch: 3/10 Iteration: 617 Train loss: 0.109\n",
      "Epoch: 3/10 Iteration: 618 Train loss: 0.103\n",
      "Epoch: 3/10 Iteration: 619 Train loss: 0.092\n",
      "Epoch: 3/10 Iteration: 620 Train loss: 0.119\n",
      "Epoch: 3/10 Iteration: 621 Train loss: 0.123\n",
      "Epoch: 3/10 Iteration: 622 Train loss: 0.125\n",
      "Epoch: 3/10 Iteration: 623 Train loss: 0.133\n",
      "Epoch: 3/10 Iteration: 624 Train loss: 0.145\n",
      "Epoch: 4/10 Iteration: 625 Train loss: 0.133\n",
      "Val acc: 0.791\n",
      "Epoch: 4/10 Iteration: 626 Train loss: 0.081\n",
      "Epoch: 4/10 Iteration: 627 Train loss: 0.121\n",
      "Epoch: 4/10 Iteration: 628 Train loss: 0.108\n",
      "Epoch: 4/10 Iteration: 629 Train loss: 0.117\n",
      "Epoch: 4/10 Iteration: 630 Train loss: 0.126\n",
      "Epoch: 4/10 Iteration: 631 Train loss: 0.152\n",
      "Epoch: 4/10 Iteration: 632 Train loss: 0.125\n",
      "Epoch: 4/10 Iteration: 633 Train loss: 0.100\n",
      "Epoch: 4/10 Iteration: 634 Train loss: 0.120\n",
      "Epoch: 4/10 Iteration: 635 Train loss: 0.104\n",
      "Epoch: 4/10 Iteration: 636 Train loss: 0.113\n",
      "Epoch: 4/10 Iteration: 637 Train loss: 0.100\n",
      "Epoch: 4/10 Iteration: 638 Train loss: 0.132\n",
      "Epoch: 4/10 Iteration: 639 Train loss: 0.139\n",
      "Epoch: 4/10 Iteration: 640 Train loss: 0.145\n",
      "Epoch: 4/10 Iteration: 641 Train loss: 0.109\n",
      "Epoch: 4/10 Iteration: 642 Train loss: 0.125\n",
      "Epoch: 4/10 Iteration: 643 Train loss: 0.125\n",
      "Epoch: 4/10 Iteration: 644 Train loss: 0.099\n",
      "Epoch: 4/10 Iteration: 645 Train loss: 0.117\n",
      "Epoch: 4/10 Iteration: 646 Train loss: 0.117\n",
      "Epoch: 4/10 Iteration: 647 Train loss: 0.121\n",
      "Epoch: 4/10 Iteration: 648 Train loss: 0.132\n",
      "Epoch: 4/10 Iteration: 649 Train loss: 0.115\n",
      "Epoch: 4/10 Iteration: 650 Train loss: 0.195\n",
      "Val acc: 0.690\n",
      "Epoch: 4/10 Iteration: 651 Train loss: 0.148\n",
      "Epoch: 4/10 Iteration: 652 Train loss: 0.123\n",
      "Epoch: 4/10 Iteration: 653 Train loss: 0.128\n",
      "Epoch: 4/10 Iteration: 654 Train loss: 0.155\n",
      "Epoch: 4/10 Iteration: 655 Train loss: 0.150\n",
      "Epoch: 4/10 Iteration: 656 Train loss: 0.135\n",
      "Epoch: 4/10 Iteration: 657 Train loss: 0.123\n",
      "Epoch: 4/10 Iteration: 658 Train loss: 0.117\n",
      "Epoch: 4/10 Iteration: 659 Train loss: 0.130\n",
      "Epoch: 4/10 Iteration: 660 Train loss: 0.133\n",
      "Epoch: 4/10 Iteration: 661 Train loss: 0.106\n",
      "Epoch: 4/10 Iteration: 662 Train loss: 0.135\n",
      "Epoch: 4/10 Iteration: 663 Train loss: 0.161\n",
      "Epoch: 4/10 Iteration: 664 Train loss: 0.124\n",
      "Epoch: 4/10 Iteration: 665 Train loss: 0.143\n",
      "Epoch: 4/10 Iteration: 666 Train loss: 0.081\n",
      "Epoch: 4/10 Iteration: 667 Train loss: 0.113\n",
      "Epoch: 4/10 Iteration: 668 Train loss: 0.141\n",
      "Epoch: 4/10 Iteration: 669 Train loss: 0.134\n",
      "Epoch: 4/10 Iteration: 670 Train loss: 0.132\n",
      "Epoch: 4/10 Iteration: 671 Train loss: 0.160\n",
      "Epoch: 4/10 Iteration: 672 Train loss: 0.141\n",
      "Epoch: 4/10 Iteration: 673 Train loss: 0.076\n",
      "Epoch: 4/10 Iteration: 674 Train loss: 0.110\n",
      "Epoch: 4/10 Iteration: 675 Train loss: 0.104\n",
      "Val acc: 0.780\n",
      "Epoch: 4/10 Iteration: 676 Train loss: 0.131\n",
      "Epoch: 4/10 Iteration: 677 Train loss: 0.132\n",
      "Epoch: 4/10 Iteration: 678 Train loss: 0.080\n",
      "Epoch: 4/10 Iteration: 679 Train loss: 0.058\n",
      "Epoch: 4/10 Iteration: 680 Train loss: 0.143\n",
      "Epoch: 4/10 Iteration: 681 Train loss: 0.116\n",
      "Epoch: 4/10 Iteration: 682 Train loss: 0.097\n",
      "Epoch: 4/10 Iteration: 683 Train loss: 0.120\n",
      "Epoch: 4/10 Iteration: 684 Train loss: 0.074\n",
      "Epoch: 4/10 Iteration: 685 Train loss: 0.124\n",
      "Epoch: 4/10 Iteration: 686 Train loss: 0.073\n",
      "Epoch: 4/10 Iteration: 687 Train loss: 0.098\n",
      "Epoch: 4/10 Iteration: 688 Train loss: 0.084\n",
      "Epoch: 4/10 Iteration: 689 Train loss: 0.121\n",
      "Epoch: 4/10 Iteration: 690 Train loss: 0.113\n",
      "Epoch: 4/10 Iteration: 691 Train loss: 0.099\n",
      "Epoch: 4/10 Iteration: 692 Train loss: 0.116\n",
      "Epoch: 4/10 Iteration: 693 Train loss: 0.102\n",
      "Epoch: 4/10 Iteration: 694 Train loss: 0.084\n",
      "Epoch: 4/10 Iteration: 695 Train loss: 0.086\n",
      "Epoch: 4/10 Iteration: 696 Train loss: 0.056\n",
      "Epoch: 4/10 Iteration: 697 Train loss: 0.088\n",
      "Epoch: 4/10 Iteration: 698 Train loss: 0.129\n",
      "Epoch: 4/10 Iteration: 699 Train loss: 0.087\n",
      "Epoch: 4/10 Iteration: 700 Train loss: 0.083\n",
      "Val acc: 0.803\n",
      "Epoch: 4/10 Iteration: 701 Train loss: 0.117\n",
      "Epoch: 4/10 Iteration: 702 Train loss: 0.101\n",
      "Epoch: 4/10 Iteration: 703 Train loss: 0.075\n",
      "Epoch: 4/10 Iteration: 704 Train loss: 0.058\n",
      "Epoch: 4/10 Iteration: 705 Train loss: 0.097\n",
      "Epoch: 4/10 Iteration: 706 Train loss: 0.046\n",
      "Epoch: 4/10 Iteration: 707 Train loss: 0.091\n",
      "Epoch: 4/10 Iteration: 708 Train loss: 0.075\n",
      "Epoch: 4/10 Iteration: 709 Train loss: 0.083\n",
      "Epoch: 4/10 Iteration: 710 Train loss: 0.063\n",
      "Epoch: 4/10 Iteration: 711 Train loss: 0.073\n",
      "Epoch: 4/10 Iteration: 712 Train loss: 0.061\n",
      "Epoch: 4/10 Iteration: 713 Train loss: 0.060\n",
      "Epoch: 4/10 Iteration: 714 Train loss: 0.101\n",
      "Epoch: 4/10 Iteration: 715 Train loss: 0.074\n",
      "Epoch: 4/10 Iteration: 716 Train loss: 0.106\n",
      "Epoch: 4/10 Iteration: 717 Train loss: 0.089\n",
      "Epoch: 4/10 Iteration: 718 Train loss: 0.050\n",
      "Epoch: 4/10 Iteration: 719 Train loss: 0.087\n",
      "Epoch: 4/10 Iteration: 720 Train loss: 0.116\n",
      "Epoch: 4/10 Iteration: 721 Train loss: 0.077\n",
      "Epoch: 4/10 Iteration: 722 Train loss: 0.054\n",
      "Epoch: 4/10 Iteration: 723 Train loss: 0.097\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4/10 Iteration: 724 Train loss: 0.069\n",
      "Epoch: 4/10 Iteration: 725 Train loss: 0.101\n",
      "Val acc: 0.823\n",
      "Epoch: 4/10 Iteration: 726 Train loss: 0.093\n",
      "Epoch: 4/10 Iteration: 727 Train loss: 0.085\n",
      "Epoch: 4/10 Iteration: 728 Train loss: 0.067\n",
      "Epoch: 4/10 Iteration: 729 Train loss: 0.065\n",
      "Epoch: 4/10 Iteration: 730 Train loss: 0.095\n",
      "Epoch: 4/10 Iteration: 731 Train loss: 0.101\n",
      "Epoch: 4/10 Iteration: 732 Train loss: 0.095\n",
      "Epoch: 4/10 Iteration: 733 Train loss: 0.056\n",
      "Epoch: 4/10 Iteration: 734 Train loss: 0.081\n",
      "Epoch: 4/10 Iteration: 735 Train loss: 0.078\n",
      "Epoch: 4/10 Iteration: 736 Train loss: 0.069\n",
      "Epoch: 4/10 Iteration: 737 Train loss: 0.135\n",
      "Epoch: 4/10 Iteration: 738 Train loss: 0.096\n",
      "Epoch: 4/10 Iteration: 739 Train loss: 0.093\n",
      "Epoch: 4/10 Iteration: 740 Train loss: 0.076\n",
      "Epoch: 4/10 Iteration: 741 Train loss: 0.074\n",
      "Epoch: 4/10 Iteration: 742 Train loss: 0.077\n",
      "Epoch: 4/10 Iteration: 743 Train loss: 0.082\n",
      "Epoch: 4/10 Iteration: 744 Train loss: 0.051\n",
      "Epoch: 4/10 Iteration: 745 Train loss: 0.041\n",
      "Epoch: 4/10 Iteration: 746 Train loss: 0.061\n",
      "Epoch: 4/10 Iteration: 747 Train loss: 0.080\n",
      "Epoch: 4/10 Iteration: 748 Train loss: 0.066\n",
      "Epoch: 4/10 Iteration: 749 Train loss: 0.077\n",
      "Epoch: 4/10 Iteration: 750 Train loss: 0.046\n",
      "Val acc: 0.879\n",
      "Epoch: 4/10 Iteration: 751 Train loss: 0.046\n",
      "Epoch: 4/10 Iteration: 752 Train loss: 0.065\n",
      "Epoch: 4/10 Iteration: 753 Train loss: 0.057\n",
      "Epoch: 4/10 Iteration: 754 Train loss: 0.023\n",
      "Epoch: 4/10 Iteration: 755 Train loss: 0.018\n",
      "Epoch: 4/10 Iteration: 756 Train loss: 0.021\n",
      "Epoch: 4/10 Iteration: 757 Train loss: 0.025\n",
      "Epoch: 4/10 Iteration: 758 Train loss: 0.016\n",
      "Epoch: 4/10 Iteration: 759 Train loss: 0.016\n",
      "Epoch: 4/10 Iteration: 760 Train loss: 0.005\n",
      "Epoch: 4/10 Iteration: 761 Train loss: 0.008\n",
      "Epoch: 4/10 Iteration: 762 Train loss: 0.019\n",
      "Epoch: 4/10 Iteration: 763 Train loss: 0.004\n",
      "Epoch: 4/10 Iteration: 764 Train loss: 0.013\n",
      "Epoch: 4/10 Iteration: 765 Train loss: 0.003\n",
      "Epoch: 4/10 Iteration: 766 Train loss: 0.001\n",
      "Epoch: 4/10 Iteration: 767 Train loss: 0.001\n",
      "Epoch: 4/10 Iteration: 768 Train loss: 0.002\n",
      "Epoch: 4/10 Iteration: 769 Train loss: 0.004\n",
      "Epoch: 4/10 Iteration: 770 Train loss: 0.001\n",
      "Epoch: 4/10 Iteration: 771 Train loss: 0.001\n",
      "Epoch: 4/10 Iteration: 772 Train loss: 0.001\n",
      "Epoch: 4/10 Iteration: 773 Train loss: 0.001\n",
      "Epoch: 4/10 Iteration: 774 Train loss: 0.001\n",
      "Epoch: 4/10 Iteration: 775 Train loss: 0.001\n",
      "Val acc: 0.870\n",
      "Epoch: 4/10 Iteration: 776 Train loss: 0.001\n",
      "Epoch: 4/10 Iteration: 777 Train loss: 0.001\n",
      "Epoch: 4/10 Iteration: 778 Train loss: 0.000\n",
      "Epoch: 4/10 Iteration: 779 Train loss: 0.000\n",
      "Epoch: 4/10 Iteration: 780 Train loss: 0.000\n",
      "Epoch: 5/10 Iteration: 781 Train loss: 0.202\n",
      "Epoch: 5/10 Iteration: 782 Train loss: 0.145\n",
      "Epoch: 5/10 Iteration: 783 Train loss: 0.127\n",
      "Epoch: 5/10 Iteration: 784 Train loss: 0.122\n",
      "Epoch: 5/10 Iteration: 785 Train loss: 0.093\n",
      "Epoch: 5/10 Iteration: 786 Train loss: 0.086\n",
      "Epoch: 5/10 Iteration: 787 Train loss: 0.067\n",
      "Epoch: 5/10 Iteration: 788 Train loss: 0.053\n",
      "Epoch: 5/10 Iteration: 789 Train loss: 0.072\n",
      "Epoch: 5/10 Iteration: 790 Train loss: 0.097\n",
      "Epoch: 5/10 Iteration: 791 Train loss: 0.092\n",
      "Epoch: 5/10 Iteration: 792 Train loss: 0.053\n",
      "Epoch: 5/10 Iteration: 793 Train loss: 0.027\n",
      "Epoch: 5/10 Iteration: 794 Train loss: 0.031\n",
      "Epoch: 5/10 Iteration: 795 Train loss: 0.041\n",
      "Epoch: 5/10 Iteration: 796 Train loss: 0.054\n",
      "Epoch: 5/10 Iteration: 797 Train loss: 0.045\n",
      "Epoch: 5/10 Iteration: 798 Train loss: 0.065\n",
      "Epoch: 5/10 Iteration: 799 Train loss: 0.039\n",
      "Epoch: 5/10 Iteration: 800 Train loss: 0.026\n",
      "Val acc: 0.950\n",
      "Epoch: 5/10 Iteration: 801 Train loss: 0.009\n",
      "Epoch: 5/10 Iteration: 802 Train loss: 0.005\n",
      "Epoch: 5/10 Iteration: 803 Train loss: 0.003\n",
      "Epoch: 5/10 Iteration: 804 Train loss: 0.007\n",
      "Epoch: 5/10 Iteration: 805 Train loss: 0.005\n",
      "Epoch: 5/10 Iteration: 806 Train loss: 0.007\n",
      "Epoch: 5/10 Iteration: 807 Train loss: 0.005\n",
      "Epoch: 5/10 Iteration: 808 Train loss: 0.016\n",
      "Epoch: 5/10 Iteration: 809 Train loss: 0.007\n",
      "Epoch: 5/10 Iteration: 810 Train loss: 0.011\n",
      "Epoch: 5/10 Iteration: 811 Train loss: 0.017\n",
      "Epoch: 5/10 Iteration: 812 Train loss: 0.002\n",
      "Epoch: 5/10 Iteration: 813 Train loss: 0.004\n",
      "Epoch: 5/10 Iteration: 814 Train loss: 0.005\n",
      "Epoch: 5/10 Iteration: 815 Train loss: 0.001\n",
      "Epoch: 5/10 Iteration: 816 Train loss: 0.002\n",
      "Epoch: 5/10 Iteration: 817 Train loss: 0.001\n",
      "Epoch: 5/10 Iteration: 818 Train loss: 0.005\n",
      "Epoch: 5/10 Iteration: 819 Train loss: 0.008\n",
      "Epoch: 5/10 Iteration: 820 Train loss: 0.008\n",
      "Epoch: 5/10 Iteration: 821 Train loss: 0.008\n",
      "Epoch: 5/10 Iteration: 822 Train loss: 0.008\n",
      "Epoch: 5/10 Iteration: 823 Train loss: 0.009\n",
      "Epoch: 5/10 Iteration: 824 Train loss: 0.003\n",
      "Epoch: 5/10 Iteration: 825 Train loss: 0.008\n",
      "Val acc: 0.750\n",
      "Epoch: 5/10 Iteration: 826 Train loss: 0.008\n",
      "Epoch: 5/10 Iteration: 827 Train loss: 0.008\n",
      "Epoch: 5/10 Iteration: 828 Train loss: 0.008\n",
      "Epoch: 5/10 Iteration: 829 Train loss: 0.007\n",
      "Epoch: 5/10 Iteration: 830 Train loss: 0.008\n",
      "Epoch: 5/10 Iteration: 831 Train loss: 0.008\n",
      "Epoch: 5/10 Iteration: 832 Train loss: 0.007\n",
      "Epoch: 5/10 Iteration: 833 Train loss: 0.001\n",
      "Epoch: 5/10 Iteration: 834 Train loss: 0.001\n",
      "Epoch: 5/10 Iteration: 835 Train loss: 0.001\n",
      "Epoch: 5/10 Iteration: 836 Train loss: 0.002\n",
      "Epoch: 5/10 Iteration: 837 Train loss: 0.001\n",
      "Epoch: 5/10 Iteration: 838 Train loss: 0.000\n",
      "Epoch: 5/10 Iteration: 839 Train loss: 0.000\n",
      "Epoch: 5/10 Iteration: 840 Train loss: 0.000\n",
      "Epoch: 5/10 Iteration: 841 Train loss: 0.002\n",
      "Epoch: 5/10 Iteration: 842 Train loss: 0.000\n",
      "Epoch: 5/10 Iteration: 843 Train loss: 0.001\n",
      "Epoch: 5/10 Iteration: 844 Train loss: 0.006\n",
      "Epoch: 5/10 Iteration: 845 Train loss: 0.006\n",
      "Epoch: 5/10 Iteration: 846 Train loss: 0.000\n",
      "Epoch: 5/10 Iteration: 847 Train loss: 0.000\n",
      "Epoch: 5/10 Iteration: 848 Train loss: 0.000\n",
      "Epoch: 5/10 Iteration: 849 Train loss: 0.000\n",
      "Epoch: 5/10 Iteration: 850 Train loss: 0.000\n",
      "Val acc: 0.757\n",
      "Epoch: 5/10 Iteration: 851 Train loss: 0.000\n",
      "Epoch: 5/10 Iteration: 852 Train loss: 0.000\n",
      "Epoch: 5/10 Iteration: 853 Train loss: 0.000\n",
      "Epoch: 5/10 Iteration: 854 Train loss: 0.001\n",
      "Epoch: 5/10 Iteration: 855 Train loss: 0.001\n",
      "Epoch: 5/10 Iteration: 856 Train loss: 0.000\n",
      "Epoch: 5/10 Iteration: 857 Train loss: 0.000\n",
      "Epoch: 5/10 Iteration: 858 Train loss: 0.000\n",
      "Epoch: 5/10 Iteration: 859 Train loss: 0.004\n",
      "Epoch: 5/10 Iteration: 860 Train loss: 0.000\n",
      "Epoch: 5/10 Iteration: 861 Train loss: 0.000\n",
      "Epoch: 5/10 Iteration: 862 Train loss: 0.000\n",
      "Epoch: 5/10 Iteration: 863 Train loss: 0.000\n",
      "Epoch: 5/10 Iteration: 864 Train loss: 0.000\n",
      "Epoch: 5/10 Iteration: 865 Train loss: 0.000\n",
      "Epoch: 5/10 Iteration: 866 Train loss: 0.000\n",
      "Epoch: 5/10 Iteration: 867 Train loss: 0.000\n",
      "Epoch: 5/10 Iteration: 868 Train loss: 0.000\n",
      "Epoch: 5/10 Iteration: 869 Train loss: 0.000\n",
      "Epoch: 5/10 Iteration: 870 Train loss: 0.000\n",
      "Epoch: 5/10 Iteration: 871 Train loss: 0.000\n",
      "Epoch: 5/10 Iteration: 872 Train loss: 0.000\n",
      "Epoch: 5/10 Iteration: 873 Train loss: 0.000\n",
      "Epoch: 5/10 Iteration: 874 Train loss: 0.000\n",
      "Epoch: 5/10 Iteration: 875 Train loss: 0.006\n",
      "Val acc: 0.675\n",
      "Epoch: 5/10 Iteration: 876 Train loss: 0.000\n",
      "Epoch: 5/10 Iteration: 877 Train loss: 0.000\n",
      "Epoch: 5/10 Iteration: 878 Train loss: 0.000\n",
      "Epoch: 5/10 Iteration: 879 Train loss: 0.000\n",
      "Epoch: 5/10 Iteration: 880 Train loss: 0.000\n",
      "Epoch: 5/10 Iteration: 881 Train loss: 0.001\n",
      "Epoch: 5/10 Iteration: 882 Train loss: 0.000\n",
      "Epoch: 5/10 Iteration: 883 Train loss: 0.000\n",
      "Epoch: 5/10 Iteration: 884 Train loss: 0.000\n",
      "Epoch: 5/10 Iteration: 885 Train loss: 0.000\n",
      "Epoch: 5/10 Iteration: 886 Train loss: 0.000\n",
      "Epoch: 5/10 Iteration: 887 Train loss: 0.000\n",
      "Epoch: 5/10 Iteration: 888 Train loss: 0.000\n",
      "Epoch: 5/10 Iteration: 889 Train loss: 0.008\n",
      "Epoch: 5/10 Iteration: 890 Train loss: 0.000\n",
      "Epoch: 5/10 Iteration: 891 Train loss: 0.000\n",
      "Epoch: 5/10 Iteration: 892 Train loss: 0.000\n",
      "Epoch: 5/10 Iteration: 893 Train loss: 0.000\n",
      "Epoch: 5/10 Iteration: 894 Train loss: 0.000\n",
      "Epoch: 5/10 Iteration: 895 Train loss: 0.000\n",
      "Epoch: 5/10 Iteration: 896 Train loss: 0.000\n",
      "Epoch: 5/10 Iteration: 897 Train loss: 0.000\n",
      "Epoch: 5/10 Iteration: 898 Train loss: 0.000\n",
      "Epoch: 5/10 Iteration: 899 Train loss: 0.000\n",
      "Epoch: 5/10 Iteration: 900 Train loss: 0.000\n",
      "Val acc: 0.680\n",
      "Epoch: 5/10 Iteration: 901 Train loss: 0.000\n",
      "Epoch: 5/10 Iteration: 902 Train loss: 0.000\n",
      "Epoch: 5/10 Iteration: 903 Train loss: 0.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5/10 Iteration: 904 Train loss: 0.000\n",
      "Epoch: 5/10 Iteration: 905 Train loss: 0.000\n",
      "Epoch: 5/10 Iteration: 906 Train loss: 0.000\n",
      "Epoch: 5/10 Iteration: 907 Train loss: 0.000\n",
      "Epoch: 5/10 Iteration: 908 Train loss: 0.000\n",
      "Epoch: 5/10 Iteration: 909 Train loss: 0.000\n",
      "Epoch: 5/10 Iteration: 910 Train loss: 0.000\n",
      "Epoch: 5/10 Iteration: 911 Train loss: 0.000\n",
      "Epoch: 5/10 Iteration: 912 Train loss: 0.000\n",
      "Epoch: 5/10 Iteration: 913 Train loss: 0.000\n",
      "Epoch: 5/10 Iteration: 914 Train loss: 0.000\n",
      "Epoch: 5/10 Iteration: 915 Train loss: 0.000\n",
      "Epoch: 5/10 Iteration: 916 Train loss: 0.000\n",
      "Epoch: 5/10 Iteration: 917 Train loss: 0.000\n",
      "Epoch: 5/10 Iteration: 918 Train loss: 0.000\n",
      "Epoch: 5/10 Iteration: 919 Train loss: 0.000\n",
      "Epoch: 5/10 Iteration: 920 Train loss: 0.000\n",
      "Epoch: 5/10 Iteration: 921 Train loss: 0.000\n",
      "Epoch: 5/10 Iteration: 922 Train loss: 0.000\n",
      "Epoch: 5/10 Iteration: 923 Train loss: 0.000\n",
      "Epoch: 5/10 Iteration: 924 Train loss: 0.000\n",
      "Epoch: 5/10 Iteration: 925 Train loss: 0.000\n",
      "Val acc: 0.676\n",
      "Epoch: 5/10 Iteration: 926 Train loss: 0.000\n",
      "Epoch: 5/10 Iteration: 927 Train loss: 0.000\n",
      "Epoch: 5/10 Iteration: 928 Train loss: 0.000\n",
      "Epoch: 5/10 Iteration: 929 Train loss: 0.000\n",
      "Epoch: 5/10 Iteration: 930 Train loss: 0.000\n",
      "Epoch: 5/10 Iteration: 931 Train loss: 0.000\n",
      "Epoch: 5/10 Iteration: 932 Train loss: 0.000\n",
      "Epoch: 5/10 Iteration: 933 Train loss: 0.000\n",
      "Epoch: 5/10 Iteration: 934 Train loss: 0.000\n",
      "Epoch: 5/10 Iteration: 935 Train loss: 0.000\n",
      "Epoch: 5/10 Iteration: 936 Train loss: 0.000\n",
      "Epoch: 6/10 Iteration: 937 Train loss: 0.267\n",
      "Epoch: 6/10 Iteration: 938 Train loss: 0.207\n",
      "Epoch: 6/10 Iteration: 939 Train loss: 0.147\n",
      "Epoch: 6/10 Iteration: 940 Train loss: 0.096\n",
      "Epoch: 6/10 Iteration: 941 Train loss: 0.101\n",
      "Epoch: 6/10 Iteration: 942 Train loss: 0.144\n",
      "Epoch: 6/10 Iteration: 943 Train loss: 0.101\n",
      "Epoch: 6/10 Iteration: 944 Train loss: 0.037\n",
      "Epoch: 6/10 Iteration: 945 Train loss: 0.027\n",
      "Epoch: 6/10 Iteration: 946 Train loss: 0.021\n",
      "Epoch: 6/10 Iteration: 947 Train loss: 0.015\n",
      "Epoch: 6/10 Iteration: 948 Train loss: 0.022\n",
      "Epoch: 6/10 Iteration: 949 Train loss: 0.026\n",
      "Epoch: 6/10 Iteration: 950 Train loss: 0.033\n",
      "Val acc: 0.547\n",
      "Epoch: 6/10 Iteration: 951 Train loss: 0.041\n",
      "Epoch: 6/10 Iteration: 952 Train loss: 0.078\n",
      "Epoch: 6/10 Iteration: 953 Train loss: 0.065\n",
      "Epoch: 6/10 Iteration: 954 Train loss: 0.045\n",
      "Epoch: 6/10 Iteration: 955 Train loss: 0.035\n",
      "Epoch: 6/10 Iteration: 956 Train loss: 0.024\n",
      "Epoch: 6/10 Iteration: 957 Train loss: 0.015\n",
      "Epoch: 6/10 Iteration: 958 Train loss: 0.009\n",
      "Epoch: 6/10 Iteration: 959 Train loss: 0.007\n",
      "Epoch: 6/10 Iteration: 960 Train loss: 0.014\n",
      "Epoch: 6/10 Iteration: 961 Train loss: 0.007\n",
      "Epoch: 6/10 Iteration: 962 Train loss: 0.014\n",
      "Epoch: 6/10 Iteration: 963 Train loss: 0.015\n",
      "Epoch: 6/10 Iteration: 964 Train loss: 0.010\n",
      "Epoch: 6/10 Iteration: 965 Train loss: 0.020\n",
      "Epoch: 6/10 Iteration: 966 Train loss: 0.018\n",
      "Epoch: 6/10 Iteration: 967 Train loss: 0.023\n",
      "Epoch: 6/10 Iteration: 968 Train loss: 0.013\n",
      "Epoch: 6/10 Iteration: 969 Train loss: 0.010\n",
      "Epoch: 6/10 Iteration: 970 Train loss: 0.015\n",
      "Epoch: 6/10 Iteration: 971 Train loss: 0.005\n",
      "Epoch: 6/10 Iteration: 972 Train loss: 0.003\n",
      "Epoch: 6/10 Iteration: 973 Train loss: 0.004\n",
      "Epoch: 6/10 Iteration: 974 Train loss: 0.005\n",
      "Epoch: 6/10 Iteration: 975 Train loss: 0.004\n",
      "Val acc: 0.904\n",
      "Epoch: 6/10 Iteration: 976 Train loss: 0.001\n",
      "Epoch: 6/10 Iteration: 977 Train loss: 0.001\n",
      "Epoch: 6/10 Iteration: 978 Train loss: 0.005\n",
      "Epoch: 6/10 Iteration: 979 Train loss: 0.001\n",
      "Epoch: 6/10 Iteration: 980 Train loss: 0.001\n",
      "Epoch: 6/10 Iteration: 981 Train loss: 0.001\n",
      "Epoch: 6/10 Iteration: 982 Train loss: 0.001\n",
      "Epoch: 6/10 Iteration: 983 Train loss: 0.001\n",
      "Epoch: 6/10 Iteration: 984 Train loss: 0.001\n",
      "Epoch: 6/10 Iteration: 985 Train loss: 0.000\n",
      "Epoch: 6/10 Iteration: 986 Train loss: 0.000\n",
      "Epoch: 6/10 Iteration: 987 Train loss: 0.000\n",
      "Epoch: 6/10 Iteration: 988 Train loss: 0.002\n",
      "Epoch: 6/10 Iteration: 989 Train loss: 0.000\n",
      "Epoch: 6/10 Iteration: 990 Train loss: 0.000\n",
      "Epoch: 6/10 Iteration: 991 Train loss: 0.000\n",
      "Epoch: 6/10 Iteration: 992 Train loss: 0.000\n",
      "Epoch: 6/10 Iteration: 993 Train loss: 0.000\n",
      "Epoch: 6/10 Iteration: 994 Train loss: 0.000\n",
      "Epoch: 6/10 Iteration: 995 Train loss: 0.001\n",
      "Epoch: 6/10 Iteration: 996 Train loss: 0.000\n",
      "Epoch: 6/10 Iteration: 997 Train loss: 0.006\n",
      "Epoch: 6/10 Iteration: 998 Train loss: 0.000\n",
      "Epoch: 6/10 Iteration: 999 Train loss: 0.000\n",
      "Epoch: 6/10 Iteration: 1000 Train loss: 0.000\n",
      "Val acc: 0.655\n",
      "Epoch: 6/10 Iteration: 1001 Train loss: 0.008\n",
      "Epoch: 6/10 Iteration: 1002 Train loss: 0.000\n",
      "Epoch: 6/10 Iteration: 1003 Train loss: 0.005\n",
      "Epoch: 6/10 Iteration: 1004 Train loss: 0.000\n",
      "Epoch: 6/10 Iteration: 1005 Train loss: 0.001\n",
      "Epoch: 6/10 Iteration: 1006 Train loss: 0.000\n",
      "Epoch: 6/10 Iteration: 1007 Train loss: 0.000\n",
      "Epoch: 6/10 Iteration: 1008 Train loss: 0.000\n",
      "Epoch: 6/10 Iteration: 1009 Train loss: 0.000\n",
      "Epoch: 6/10 Iteration: 1010 Train loss: 0.004\n",
      "Epoch: 6/10 Iteration: 1011 Train loss: 0.005\n",
      "Epoch: 6/10 Iteration: 1012 Train loss: 0.000\n",
      "Epoch: 6/10 Iteration: 1013 Train loss: 0.000\n",
      "Epoch: 6/10 Iteration: 1014 Train loss: 0.000\n",
      "Epoch: 6/10 Iteration: 1015 Train loss: 0.000\n",
      "Epoch: 6/10 Iteration: 1016 Train loss: 0.000\n",
      "Epoch: 6/10 Iteration: 1017 Train loss: 0.000\n",
      "Epoch: 6/10 Iteration: 1018 Train loss: 0.000\n",
      "Epoch: 6/10 Iteration: 1019 Train loss: 0.000\n",
      "Epoch: 6/10 Iteration: 1020 Train loss: 0.002\n",
      "Epoch: 6/10 Iteration: 1021 Train loss: 0.000\n",
      "Epoch: 6/10 Iteration: 1022 Train loss: 0.000\n",
      "Epoch: 6/10 Iteration: 1023 Train loss: 0.000\n",
      "Epoch: 6/10 Iteration: 1024 Train loss: 0.000\n",
      "Epoch: 6/10 Iteration: 1025 Train loss: 0.000\n",
      "Val acc: 0.738\n",
      "Epoch: 6/10 Iteration: 1026 Train loss: 0.000\n",
      "Epoch: 6/10 Iteration: 1027 Train loss: 0.000\n",
      "Epoch: 6/10 Iteration: 1028 Train loss: 0.000\n",
      "Epoch: 6/10 Iteration: 1029 Train loss: 0.000\n",
      "Epoch: 6/10 Iteration: 1030 Train loss: 0.000\n",
      "Epoch: 6/10 Iteration: 1031 Train loss: 0.004\n",
      "Epoch: 6/10 Iteration: 1032 Train loss: 0.000\n",
      "Epoch: 6/10 Iteration: 1033 Train loss: 0.000\n",
      "Epoch: 6/10 Iteration: 1034 Train loss: 0.000\n",
      "Epoch: 6/10 Iteration: 1035 Train loss: 0.000\n",
      "Epoch: 6/10 Iteration: 1036 Train loss: 0.000\n",
      "Epoch: 6/10 Iteration: 1037 Train loss: 0.000\n",
      "Epoch: 6/10 Iteration: 1038 Train loss: 0.000\n",
      "Epoch: 6/10 Iteration: 1039 Train loss: 0.000\n",
      "Epoch: 6/10 Iteration: 1040 Train loss: 0.000\n",
      "Epoch: 6/10 Iteration: 1041 Train loss: 0.000\n",
      "Epoch: 6/10 Iteration: 1042 Train loss: 0.000\n",
      "Epoch: 6/10 Iteration: 1043 Train loss: 0.000\n",
      "Epoch: 6/10 Iteration: 1044 Train loss: 0.000\n",
      "Epoch: 6/10 Iteration: 1045 Train loss: 0.000\n",
      "Epoch: 6/10 Iteration: 1046 Train loss: 0.000\n",
      "Epoch: 6/10 Iteration: 1047 Train loss: 0.000\n",
      "Epoch: 6/10 Iteration: 1048 Train loss: 0.000\n",
      "Epoch: 6/10 Iteration: 1049 Train loss: 0.000\n",
      "Epoch: 6/10 Iteration: 1050 Train loss: 0.000\n",
      "Val acc: 0.733\n",
      "Epoch: 6/10 Iteration: 1051 Train loss: 0.000\n",
      "Epoch: 6/10 Iteration: 1052 Train loss: 0.000\n",
      "Epoch: 6/10 Iteration: 1053 Train loss: 0.000\n",
      "Epoch: 6/10 Iteration: 1054 Train loss: 0.000\n",
      "Epoch: 6/10 Iteration: 1055 Train loss: 0.000\n",
      "Epoch: 6/10 Iteration: 1056 Train loss: 0.000\n",
      "Epoch: 6/10 Iteration: 1057 Train loss: 0.000\n",
      "Epoch: 6/10 Iteration: 1058 Train loss: 0.000\n",
      "Epoch: 6/10 Iteration: 1059 Train loss: 0.000\n",
      "Epoch: 6/10 Iteration: 1060 Train loss: 0.000\n",
      "Epoch: 6/10 Iteration: 1061 Train loss: 0.000\n",
      "Epoch: 6/10 Iteration: 1062 Train loss: 0.000\n",
      "Epoch: 6/10 Iteration: 1063 Train loss: 0.000\n",
      "Epoch: 6/10 Iteration: 1064 Train loss: 0.000\n",
      "Epoch: 6/10 Iteration: 1065 Train loss: 0.000\n",
      "Epoch: 6/10 Iteration: 1066 Train loss: 0.000\n",
      "Epoch: 6/10 Iteration: 1067 Train loss: 0.000\n",
      "Epoch: 6/10 Iteration: 1068 Train loss: 0.000\n",
      "Epoch: 6/10 Iteration: 1069 Train loss: 0.000\n",
      "Epoch: 6/10 Iteration: 1070 Train loss: 0.000\n",
      "Epoch: 6/10 Iteration: 1071 Train loss: 0.000\n",
      "Epoch: 6/10 Iteration: 1072 Train loss: 0.000\n",
      "Epoch: 6/10 Iteration: 1073 Train loss: 0.000\n",
      "Epoch: 6/10 Iteration: 1074 Train loss: 0.001\n",
      "Epoch: 6/10 Iteration: 1075 Train loss: 0.000\n",
      "Val acc: 0.738\n",
      "Epoch: 6/10 Iteration: 1076 Train loss: 0.000\n",
      "Epoch: 6/10 Iteration: 1077 Train loss: 0.000\n",
      "Epoch: 6/10 Iteration: 1078 Train loss: 0.000\n",
      "Epoch: 6/10 Iteration: 1079 Train loss: 0.000\n",
      "Epoch: 6/10 Iteration: 1080 Train loss: 0.000\n",
      "Epoch: 6/10 Iteration: 1081 Train loss: 0.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6/10 Iteration: 1082 Train loss: 0.000\n",
      "Epoch: 6/10 Iteration: 1083 Train loss: 0.000\n",
      "Epoch: 6/10 Iteration: 1084 Train loss: 0.000\n",
      "Epoch: 6/10 Iteration: 1085 Train loss: 0.000\n",
      "Epoch: 6/10 Iteration: 1086 Train loss: 0.000\n",
      "Epoch: 6/10 Iteration: 1087 Train loss: 0.000\n",
      "Epoch: 6/10 Iteration: 1088 Train loss: 0.000\n",
      "Epoch: 6/10 Iteration: 1089 Train loss: 0.000\n",
      "Epoch: 6/10 Iteration: 1090 Train loss: 0.000\n",
      "Epoch: 6/10 Iteration: 1091 Train loss: 0.000\n",
      "Epoch: 6/10 Iteration: 1092 Train loss: 0.000\n",
      "Epoch: 7/10 Iteration: 1093 Train loss: 0.246\n",
      "Epoch: 7/10 Iteration: 1094 Train loss: 0.151\n",
      "Epoch: 7/10 Iteration: 1095 Train loss: 0.122\n",
      "Epoch: 7/10 Iteration: 1096 Train loss: 0.089\n",
      "Epoch: 7/10 Iteration: 1097 Train loss: 0.055\n",
      "Epoch: 7/10 Iteration: 1098 Train loss: 0.031\n",
      "Epoch: 7/10 Iteration: 1099 Train loss: 0.045\n",
      "Epoch: 7/10 Iteration: 1100 Train loss: 0.130\n",
      "Val acc: 0.505\n",
      "Epoch: 7/10 Iteration: 1101 Train loss: 0.238\n",
      "Epoch: 7/10 Iteration: 1102 Train loss: 0.372\n",
      "Epoch: 7/10 Iteration: 1103 Train loss: 0.392\n",
      "Epoch: 7/10 Iteration: 1104 Train loss: 0.425\n",
      "Epoch: 7/10 Iteration: 1105 Train loss: 0.430\n",
      "Epoch: 7/10 Iteration: 1106 Train loss: 0.421\n",
      "Epoch: 7/10 Iteration: 1107 Train loss: 0.390\n",
      "Epoch: 7/10 Iteration: 1108 Train loss: 0.373\n",
      "Epoch: 7/10 Iteration: 1109 Train loss: 0.300\n",
      "Epoch: 7/10 Iteration: 1110 Train loss: 0.216\n",
      "Epoch: 7/10 Iteration: 1111 Train loss: 0.113\n",
      "Epoch: 7/10 Iteration: 1112 Train loss: 0.051\n",
      "Epoch: 7/10 Iteration: 1113 Train loss: 0.056\n",
      "Epoch: 7/10 Iteration: 1114 Train loss: 0.053\n",
      "Epoch: 7/10 Iteration: 1115 Train loss: 0.110\n",
      "Epoch: 7/10 Iteration: 1116 Train loss: 0.145\n",
      "Epoch: 7/10 Iteration: 1117 Train loss: 0.161\n",
      "Epoch: 7/10 Iteration: 1118 Train loss: 0.211\n",
      "Epoch: 7/10 Iteration: 1119 Train loss: 0.187\n",
      "Epoch: 7/10 Iteration: 1120 Train loss: 0.168\n",
      "Epoch: 7/10 Iteration: 1121 Train loss: 0.187\n",
      "Epoch: 7/10 Iteration: 1122 Train loss: 0.133\n",
      "Epoch: 7/10 Iteration: 1123 Train loss: 0.100\n",
      "Epoch: 7/10 Iteration: 1124 Train loss: 0.080\n",
      "Epoch: 7/10 Iteration: 1125 Train loss: 0.054\n",
      "Val acc: 0.909\n",
      "Epoch: 7/10 Iteration: 1126 Train loss: 0.036\n",
      "Epoch: 7/10 Iteration: 1127 Train loss: 0.036\n",
      "Epoch: 7/10 Iteration: 1128 Train loss: 0.059\n",
      "Epoch: 7/10 Iteration: 1129 Train loss: 0.062\n",
      "Epoch: 7/10 Iteration: 1130 Train loss: 0.084\n",
      "Epoch: 7/10 Iteration: 1131 Train loss: 0.098\n",
      "Epoch: 7/10 Iteration: 1132 Train loss: 0.097\n",
      "Epoch: 7/10 Iteration: 1133 Train loss: 0.115\n",
      "Epoch: 7/10 Iteration: 1134 Train loss: 0.118\n",
      "Epoch: 7/10 Iteration: 1135 Train loss: 0.114\n",
      "Epoch: 7/10 Iteration: 1136 Train loss: 0.122\n",
      "Epoch: 7/10 Iteration: 1137 Train loss: 0.100\n",
      "Epoch: 7/10 Iteration: 1138 Train loss: 0.085\n",
      "Epoch: 7/10 Iteration: 1139 Train loss: 0.082\n",
      "Epoch: 7/10 Iteration: 1140 Train loss: 0.050\n",
      "Epoch: 7/10 Iteration: 1141 Train loss: 0.029\n",
      "Epoch: 7/10 Iteration: 1142 Train loss: 0.026\n",
      "Epoch: 7/10 Iteration: 1143 Train loss: 0.023\n",
      "Epoch: 7/10 Iteration: 1144 Train loss: 0.024\n",
      "Epoch: 7/10 Iteration: 1145 Train loss: 0.025\n",
      "Epoch: 7/10 Iteration: 1146 Train loss: 0.023\n",
      "Epoch: 7/10 Iteration: 1147 Train loss: 0.018\n",
      "Epoch: 7/10 Iteration: 1148 Train loss: 0.035\n",
      "Epoch: 7/10 Iteration: 1149 Train loss: 0.024\n",
      "Epoch: 7/10 Iteration: 1150 Train loss: 0.041\n",
      "Val acc: 0.624\n",
      "Epoch: 7/10 Iteration: 1151 Train loss: 0.022\n",
      "Epoch: 7/10 Iteration: 1152 Train loss: 0.019\n",
      "Epoch: 7/10 Iteration: 1153 Train loss: 0.056\n",
      "Epoch: 7/10 Iteration: 1154 Train loss: 0.036\n",
      "Epoch: 7/10 Iteration: 1155 Train loss: 0.044\n",
      "Epoch: 7/10 Iteration: 1156 Train loss: 0.037\n",
      "Epoch: 7/10 Iteration: 1157 Train loss: 0.059\n",
      "Epoch: 7/10 Iteration: 1158 Train loss: 0.030\n",
      "Epoch: 7/10 Iteration: 1159 Train loss: 0.032\n",
      "Epoch: 7/10 Iteration: 1160 Train loss: 0.020\n",
      "Epoch: 7/10 Iteration: 1161 Train loss: 0.016\n",
      "Epoch: 7/10 Iteration: 1162 Train loss: 0.014\n",
      "Epoch: 7/10 Iteration: 1163 Train loss: 0.018\n",
      "Epoch: 7/10 Iteration: 1164 Train loss: 0.012\n",
      "Epoch: 7/10 Iteration: 1165 Train loss: 0.011\n",
      "Epoch: 7/10 Iteration: 1166 Train loss: 0.010\n",
      "Epoch: 7/10 Iteration: 1167 Train loss: 0.008\n",
      "Epoch: 7/10 Iteration: 1168 Train loss: 0.002\n",
      "Epoch: 7/10 Iteration: 1169 Train loss: 0.003\n",
      "Epoch: 7/10 Iteration: 1170 Train loss: 0.003\n",
      "Epoch: 7/10 Iteration: 1171 Train loss: 0.004\n",
      "Epoch: 7/10 Iteration: 1172 Train loss: 0.004\n",
      "Epoch: 7/10 Iteration: 1173 Train loss: 0.009\n",
      "Epoch: 7/10 Iteration: 1174 Train loss: 0.003\n",
      "Epoch: 7/10 Iteration: 1175 Train loss: 0.002\n",
      "Val acc: 0.949\n",
      "Epoch: 7/10 Iteration: 1176 Train loss: 0.005\n",
      "Epoch: 7/10 Iteration: 1177 Train loss: 0.003\n",
      "Epoch: 7/10 Iteration: 1178 Train loss: 0.002\n",
      "Epoch: 7/10 Iteration: 1179 Train loss: 0.002\n",
      "Epoch: 7/10 Iteration: 1180 Train loss: 0.002\n",
      "Epoch: 7/10 Iteration: 1181 Train loss: 0.002\n",
      "Epoch: 7/10 Iteration: 1182 Train loss: 0.003\n",
      "Epoch: 7/10 Iteration: 1183 Train loss: 0.002\n",
      "Epoch: 7/10 Iteration: 1184 Train loss: 0.002\n",
      "Epoch: 7/10 Iteration: 1185 Train loss: 0.001\n",
      "Epoch: 7/10 Iteration: 1186 Train loss: 0.004\n",
      "Epoch: 7/10 Iteration: 1187 Train loss: 0.004\n",
      "Epoch: 7/10 Iteration: 1188 Train loss: 0.001\n",
      "Epoch: 7/10 Iteration: 1189 Train loss: 0.001\n",
      "Epoch: 7/10 Iteration: 1190 Train loss: 0.001\n",
      "Epoch: 7/10 Iteration: 1191 Train loss: 0.001\n",
      "Epoch: 7/10 Iteration: 1192 Train loss: 0.001\n",
      "Epoch: 7/10 Iteration: 1193 Train loss: 0.001\n",
      "Epoch: 7/10 Iteration: 1194 Train loss: 0.002\n",
      "Epoch: 7/10 Iteration: 1195 Train loss: 0.001\n",
      "Epoch: 7/10 Iteration: 1196 Train loss: 0.001\n",
      "Epoch: 7/10 Iteration: 1197 Train loss: 0.001\n",
      "Epoch: 7/10 Iteration: 1198 Train loss: 0.001\n",
      "Epoch: 7/10 Iteration: 1199 Train loss: 0.001\n",
      "Epoch: 7/10 Iteration: 1200 Train loss: 0.001\n",
      "Val acc: 0.924\n",
      "Epoch: 7/10 Iteration: 1201 Train loss: 0.005\n",
      "Epoch: 7/10 Iteration: 1202 Train loss: 0.001\n",
      "Epoch: 7/10 Iteration: 1203 Train loss: 0.001\n",
      "Epoch: 7/10 Iteration: 1204 Train loss: 0.001\n",
      "Epoch: 7/10 Iteration: 1205 Train loss: 0.001\n",
      "Epoch: 7/10 Iteration: 1206 Train loss: 0.001\n",
      "Epoch: 7/10 Iteration: 1207 Train loss: 0.001\n",
      "Epoch: 7/10 Iteration: 1208 Train loss: 0.001\n",
      "Epoch: 7/10 Iteration: 1209 Train loss: 0.000\n",
      "Epoch: 7/10 Iteration: 1210 Train loss: 0.000\n",
      "Epoch: 7/10 Iteration: 1211 Train loss: 0.000\n",
      "Epoch: 7/10 Iteration: 1212 Train loss: 0.000\n",
      "Epoch: 7/10 Iteration: 1213 Train loss: 0.000\n",
      "Epoch: 7/10 Iteration: 1214 Train loss: 0.000\n",
      "Epoch: 7/10 Iteration: 1215 Train loss: 0.000\n",
      "Epoch: 7/10 Iteration: 1216 Train loss: 0.000\n",
      "Epoch: 7/10 Iteration: 1217 Train loss: 0.000\n",
      "Epoch: 7/10 Iteration: 1218 Train loss: 0.000\n",
      "Epoch: 7/10 Iteration: 1219 Train loss: 0.001\n",
      "Epoch: 7/10 Iteration: 1220 Train loss: 0.001\n",
      "Epoch: 7/10 Iteration: 1221 Train loss: 0.000\n",
      "Epoch: 7/10 Iteration: 1222 Train loss: 0.002\n",
      "Epoch: 7/10 Iteration: 1223 Train loss: 0.000\n",
      "Epoch: 7/10 Iteration: 1224 Train loss: 0.001\n",
      "Epoch: 7/10 Iteration: 1225 Train loss: 0.001\n",
      "Val acc: 0.924\n",
      "Epoch: 7/10 Iteration: 1226 Train loss: 0.000\n",
      "Epoch: 7/10 Iteration: 1227 Train loss: 0.000\n",
      "Epoch: 7/10 Iteration: 1228 Train loss: 0.000\n",
      "Epoch: 7/10 Iteration: 1229 Train loss: 0.000\n",
      "Epoch: 7/10 Iteration: 1230 Train loss: 0.002\n",
      "Epoch: 7/10 Iteration: 1231 Train loss: 0.000\n",
      "Epoch: 7/10 Iteration: 1232 Train loss: 0.000\n",
      "Epoch: 7/10 Iteration: 1233 Train loss: 0.000\n",
      "Epoch: 7/10 Iteration: 1234 Train loss: 0.000\n",
      "Epoch: 7/10 Iteration: 1235 Train loss: 0.000\n",
      "Epoch: 7/10 Iteration: 1236 Train loss: 0.000\n",
      "Epoch: 7/10 Iteration: 1237 Train loss: 0.000\n",
      "Epoch: 7/10 Iteration: 1238 Train loss: 0.000\n",
      "Epoch: 7/10 Iteration: 1239 Train loss: 0.000\n",
      "Epoch: 7/10 Iteration: 1240 Train loss: 0.000\n",
      "Epoch: 7/10 Iteration: 1241 Train loss: 0.000\n",
      "Epoch: 7/10 Iteration: 1242 Train loss: 0.000\n",
      "Epoch: 7/10 Iteration: 1243 Train loss: 0.000\n",
      "Epoch: 7/10 Iteration: 1244 Train loss: 0.000\n",
      "Epoch: 7/10 Iteration: 1245 Train loss: 0.000\n",
      "Epoch: 7/10 Iteration: 1246 Train loss: 0.000\n",
      "Epoch: 7/10 Iteration: 1247 Train loss: 0.000\n",
      "Epoch: 7/10 Iteration: 1248 Train loss: 0.000\n",
      "Epoch: 8/10 Iteration: 1249 Train loss: 0.116\n",
      "Epoch: 8/10 Iteration: 1250 Train loss: 0.048\n",
      "Val acc: 0.956\n",
      "Epoch: 8/10 Iteration: 1251 Train loss: 0.035\n",
      "Epoch: 8/10 Iteration: 1252 Train loss: 0.025\n",
      "Epoch: 8/10 Iteration: 1253 Train loss: 0.028\n",
      "Epoch: 8/10 Iteration: 1254 Train loss: 0.015\n",
      "Epoch: 8/10 Iteration: 1255 Train loss: 0.009\n",
      "Epoch: 8/10 Iteration: 1256 Train loss: 0.007\n",
      "Epoch: 8/10 Iteration: 1257 Train loss: 0.007\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8/10 Iteration: 1258 Train loss: 0.000\n",
      "Epoch: 8/10 Iteration: 1259 Train loss: 0.000\n",
      "Epoch: 8/10 Iteration: 1260 Train loss: 0.000\n",
      "Epoch: 8/10 Iteration: 1261 Train loss: 0.000\n",
      "Epoch: 8/10 Iteration: 1262 Train loss: 0.002\n",
      "Epoch: 8/10 Iteration: 1263 Train loss: 0.000\n",
      "Epoch: 8/10 Iteration: 1264 Train loss: 0.008\n",
      "Epoch: 8/10 Iteration: 1265 Train loss: 0.008\n",
      "Epoch: 8/10 Iteration: 1266 Train loss: 0.008\n",
      "Epoch: 8/10 Iteration: 1267 Train loss: 0.007\n",
      "Epoch: 8/10 Iteration: 1268 Train loss: 0.008\n",
      "Epoch: 8/10 Iteration: 1269 Train loss: 0.007\n",
      "Epoch: 8/10 Iteration: 1270 Train loss: 0.006\n",
      "Epoch: 8/10 Iteration: 1271 Train loss: 0.000\n",
      "Epoch: 8/10 Iteration: 1272 Train loss: 0.008\n",
      "Epoch: 8/10 Iteration: 1273 Train loss: 0.000\n",
      "Epoch: 8/10 Iteration: 1274 Train loss: 0.000\n",
      "Epoch: 8/10 Iteration: 1275 Train loss: 0.000\n",
      "Val acc: 0.889\n",
      "Epoch: 8/10 Iteration: 1276 Train loss: 0.001\n",
      "Epoch: 8/10 Iteration: 1277 Train loss: 0.000\n",
      "Epoch: 8/10 Iteration: 1278 Train loss: 0.001\n",
      "Epoch: 8/10 Iteration: 1279 Train loss: 0.003\n",
      "Epoch: 8/10 Iteration: 1280 Train loss: 0.000\n",
      "Epoch: 8/10 Iteration: 1281 Train loss: 0.001\n",
      "Epoch: 8/10 Iteration: 1282 Train loss: 0.000\n",
      "Epoch: 8/10 Iteration: 1283 Train loss: 0.000\n",
      "Epoch: 8/10 Iteration: 1284 Train loss: 0.001\n",
      "Epoch: 8/10 Iteration: 1285 Train loss: 0.000\n",
      "Epoch: 8/10 Iteration: 1286 Train loss: 0.008\n",
      "Epoch: 8/10 Iteration: 1287 Train loss: 0.008\n",
      "Epoch: 8/10 Iteration: 1288 Train loss: 0.007\n",
      "Epoch: 8/10 Iteration: 1289 Train loss: 0.004\n",
      "Epoch: 8/10 Iteration: 1290 Train loss: 0.008\n",
      "Epoch: 8/10 Iteration: 1291 Train loss: 0.008\n",
      "Epoch: 8/10 Iteration: 1292 Train loss: 0.000\n",
      "Epoch: 8/10 Iteration: 1293 Train loss: 0.001\n",
      "Epoch: 8/10 Iteration: 1294 Train loss: 0.001\n",
      "Epoch: 8/10 Iteration: 1295 Train loss: 0.007\n",
      "Epoch: 8/10 Iteration: 1296 Train loss: 0.004\n",
      "Epoch: 8/10 Iteration: 1297 Train loss: 0.005\n",
      "Epoch: 8/10 Iteration: 1298 Train loss: 0.006\n",
      "Epoch: 8/10 Iteration: 1299 Train loss: 0.000\n",
      "Epoch: 8/10 Iteration: 1300 Train loss: 0.001\n",
      "Val acc: 0.946\n",
      "Epoch: 8/10 Iteration: 1301 Train loss: 0.000\n",
      "Epoch: 8/10 Iteration: 1302 Train loss: 0.000\n",
      "Epoch: 8/10 Iteration: 1303 Train loss: 0.000\n",
      "Epoch: 8/10 Iteration: 1304 Train loss: 0.001\n",
      "Epoch: 8/10 Iteration: 1305 Train loss: 0.000\n",
      "Epoch: 8/10 Iteration: 1306 Train loss: 0.000\n",
      "Epoch: 8/10 Iteration: 1307 Train loss: 0.000\n",
      "Epoch: 8/10 Iteration: 1308 Train loss: 0.000\n",
      "Epoch: 8/10 Iteration: 1309 Train loss: 0.001\n",
      "Epoch: 8/10 Iteration: 1310 Train loss: 0.000\n",
      "Epoch: 8/10 Iteration: 1311 Train loss: 0.000\n",
      "Epoch: 8/10 Iteration: 1312 Train loss: 0.001\n",
      "Epoch: 8/10 Iteration: 1313 Train loss: 0.002\n",
      "Epoch: 8/10 Iteration: 1314 Train loss: 0.000\n",
      "Epoch: 8/10 Iteration: 1315 Train loss: 0.001\n",
      "Epoch: 8/10 Iteration: 1316 Train loss: 0.001\n",
      "Epoch: 8/10 Iteration: 1317 Train loss: 0.000\n",
      "Epoch: 8/10 Iteration: 1318 Train loss: 0.000\n",
      "Epoch: 8/10 Iteration: 1319 Train loss: 0.000\n",
      "Epoch: 8/10 Iteration: 1320 Train loss: 0.000\n",
      "Epoch: 8/10 Iteration: 1321 Train loss: 0.000\n",
      "Epoch: 8/10 Iteration: 1322 Train loss: 0.001\n",
      "Epoch: 8/10 Iteration: 1323 Train loss: 0.000\n",
      "Epoch: 8/10 Iteration: 1324 Train loss: 0.000\n",
      "Epoch: 8/10 Iteration: 1325 Train loss: 0.000\n",
      "Val acc: 0.960\n",
      "Epoch: 8/10 Iteration: 1326 Train loss: 0.001\n",
      "Epoch: 8/10 Iteration: 1327 Train loss: 0.000\n",
      "Epoch: 8/10 Iteration: 1328 Train loss: 0.000\n",
      "Epoch: 8/10 Iteration: 1329 Train loss: 0.000\n",
      "Epoch: 8/10 Iteration: 1330 Train loss: 0.001\n",
      "Epoch: 8/10 Iteration: 1331 Train loss: 0.000\n",
      "Epoch: 8/10 Iteration: 1332 Train loss: 0.000\n",
      "Epoch: 8/10 Iteration: 1333 Train loss: 0.000\n",
      "Epoch: 8/10 Iteration: 1334 Train loss: 0.000\n",
      "Epoch: 8/10 Iteration: 1335 Train loss: 0.000\n",
      "Epoch: 8/10 Iteration: 1336 Train loss: 0.000\n",
      "Epoch: 8/10 Iteration: 1337 Train loss: 0.000\n",
      "Epoch: 8/10 Iteration: 1338 Train loss: 0.001\n",
      "Epoch: 8/10 Iteration: 1339 Train loss: 0.000\n",
      "Epoch: 8/10 Iteration: 1340 Train loss: 0.000\n",
      "Epoch: 8/10 Iteration: 1341 Train loss: 0.000\n",
      "Epoch: 8/10 Iteration: 1342 Train loss: 0.000\n",
      "Epoch: 8/10 Iteration: 1343 Train loss: 0.001\n",
      "Epoch: 8/10 Iteration: 1344 Train loss: 0.000\n",
      "Epoch: 8/10 Iteration: 1345 Train loss: 0.000\n",
      "Epoch: 8/10 Iteration: 1346 Train loss: 0.000\n",
      "Epoch: 8/10 Iteration: 1347 Train loss: 0.000\n",
      "Epoch: 8/10 Iteration: 1348 Train loss: 0.000\n",
      "Epoch: 8/10 Iteration: 1349 Train loss: 0.000\n",
      "Epoch: 8/10 Iteration: 1350 Train loss: 0.000\n",
      "Val acc: 0.961\n",
      "Epoch: 8/10 Iteration: 1351 Train loss: 0.000\n",
      "Epoch: 8/10 Iteration: 1352 Train loss: 0.000\n",
      "Epoch: 8/10 Iteration: 1353 Train loss: 0.000\n",
      "Epoch: 8/10 Iteration: 1354 Train loss: 0.000\n",
      "Epoch: 8/10 Iteration: 1355 Train loss: 0.000\n",
      "Epoch: 8/10 Iteration: 1356 Train loss: 0.000\n",
      "Epoch: 8/10 Iteration: 1357 Train loss: 0.003\n",
      "Epoch: 8/10 Iteration: 1358 Train loss: 0.000\n",
      "Epoch: 8/10 Iteration: 1359 Train loss: 0.000\n",
      "Epoch: 8/10 Iteration: 1360 Train loss: 0.000\n",
      "Epoch: 8/10 Iteration: 1361 Train loss: 0.000\n",
      "Epoch: 8/10 Iteration: 1362 Train loss: 0.001\n",
      "Epoch: 8/10 Iteration: 1363 Train loss: 0.000\n",
      "Epoch: 8/10 Iteration: 1364 Train loss: 0.000\n",
      "Epoch: 8/10 Iteration: 1365 Train loss: 0.000\n",
      "Epoch: 8/10 Iteration: 1366 Train loss: 0.000\n",
      "Epoch: 8/10 Iteration: 1367 Train loss: 0.000\n",
      "Epoch: 8/10 Iteration: 1368 Train loss: 0.000\n",
      "Epoch: 8/10 Iteration: 1369 Train loss: 0.000\n",
      "Epoch: 8/10 Iteration: 1370 Train loss: 0.000\n",
      "Epoch: 8/10 Iteration: 1371 Train loss: 0.000\n",
      "Epoch: 8/10 Iteration: 1372 Train loss: 0.000\n",
      "Epoch: 8/10 Iteration: 1373 Train loss: 0.000\n",
      "Epoch: 8/10 Iteration: 1374 Train loss: 0.000\n",
      "Epoch: 8/10 Iteration: 1375 Train loss: 0.000\n",
      "Val acc: 0.963\n",
      "Epoch: 8/10 Iteration: 1376 Train loss: 0.000\n",
      "Epoch: 8/10 Iteration: 1377 Train loss: 0.000\n",
      "Epoch: 8/10 Iteration: 1378 Train loss: 0.000\n",
      "Epoch: 8/10 Iteration: 1379 Train loss: 0.000\n",
      "Epoch: 8/10 Iteration: 1380 Train loss: 0.000\n",
      "Epoch: 8/10 Iteration: 1381 Train loss: 0.000\n",
      "Epoch: 8/10 Iteration: 1382 Train loss: 0.000\n",
      "Epoch: 8/10 Iteration: 1383 Train loss: 0.000\n",
      "Epoch: 8/10 Iteration: 1384 Train loss: 0.000\n",
      "Epoch: 8/10 Iteration: 1385 Train loss: 0.000\n",
      "Epoch: 8/10 Iteration: 1386 Train loss: 0.000\n",
      "Epoch: 8/10 Iteration: 1387 Train loss: 0.000\n",
      "Epoch: 8/10 Iteration: 1388 Train loss: 0.000\n",
      "Epoch: 8/10 Iteration: 1389 Train loss: 0.000\n",
      "Epoch: 8/10 Iteration: 1390 Train loss: 0.000\n",
      "Epoch: 8/10 Iteration: 1391 Train loss: 0.000\n",
      "Epoch: 8/10 Iteration: 1392 Train loss: 0.000\n",
      "Epoch: 8/10 Iteration: 1393 Train loss: 0.000\n",
      "Epoch: 8/10 Iteration: 1394 Train loss: 0.000\n",
      "Epoch: 8/10 Iteration: 1395 Train loss: 0.000\n",
      "Epoch: 8/10 Iteration: 1396 Train loss: 0.000\n",
      "Epoch: 8/10 Iteration: 1397 Train loss: 0.000\n",
      "Epoch: 8/10 Iteration: 1398 Train loss: 0.000\n",
      "Epoch: 8/10 Iteration: 1399 Train loss: 0.000\n",
      "Epoch: 8/10 Iteration: 1400 Train loss: 0.000\n",
      "Val acc: 0.964\n",
      "Epoch: 8/10 Iteration: 1401 Train loss: 0.000\n",
      "Epoch: 8/10 Iteration: 1402 Train loss: 0.000\n",
      "Epoch: 8/10 Iteration: 1403 Train loss: 0.000\n",
      "Epoch: 8/10 Iteration: 1404 Train loss: 0.000\n",
      "Epoch: 9/10 Iteration: 1405 Train loss: 0.060\n",
      "Epoch: 9/10 Iteration: 1406 Train loss: 0.029\n",
      "Epoch: 9/10 Iteration: 1407 Train loss: 0.024\n",
      "Epoch: 9/10 Iteration: 1408 Train loss: 0.021\n",
      "Epoch: 9/10 Iteration: 1409 Train loss: 0.015\n",
      "Epoch: 9/10 Iteration: 1410 Train loss: 0.007\n",
      "Epoch: 9/10 Iteration: 1411 Train loss: 0.008\n",
      "Epoch: 9/10 Iteration: 1412 Train loss: 0.002\n",
      "Epoch: 9/10 Iteration: 1413 Train loss: 0.000\n",
      "Epoch: 9/10 Iteration: 1414 Train loss: 0.000\n",
      "Epoch: 9/10 Iteration: 1415 Train loss: 0.000\n",
      "Epoch: 9/10 Iteration: 1416 Train loss: 0.000\n",
      "Epoch: 9/10 Iteration: 1417 Train loss: 0.000\n",
      "Epoch: 9/10 Iteration: 1418 Train loss: 0.000\n",
      "Epoch: 9/10 Iteration: 1419 Train loss: 0.000\n",
      "Epoch: 9/10 Iteration: 1420 Train loss: 0.008\n",
      "Epoch: 9/10 Iteration: 1421 Train loss: 0.000\n",
      "Epoch: 9/10 Iteration: 1422 Train loss: 0.000\n",
      "Epoch: 9/10 Iteration: 1423 Train loss: 0.000\n",
      "Epoch: 9/10 Iteration: 1424 Train loss: 0.002\n",
      "Epoch: 9/10 Iteration: 1425 Train loss: 0.000\n",
      "Val acc: 0.967\n",
      "Epoch: 9/10 Iteration: 1426 Train loss: 0.000\n",
      "Epoch: 9/10 Iteration: 1427 Train loss: 0.000\n",
      "Epoch: 9/10 Iteration: 1428 Train loss: 0.000\n",
      "Epoch: 9/10 Iteration: 1429 Train loss: 0.000\n",
      "Epoch: 9/10 Iteration: 1430 Train loss: 0.000\n",
      "Epoch: 9/10 Iteration: 1431 Train loss: 0.001\n",
      "Epoch: 9/10 Iteration: 1432 Train loss: 0.000\n",
      "Epoch: 9/10 Iteration: 1433 Train loss: 0.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9/10 Iteration: 1434 Train loss: 0.000\n",
      "Epoch: 9/10 Iteration: 1435 Train loss: 0.002\n",
      "Epoch: 9/10 Iteration: 1436 Train loss: 0.000\n",
      "Epoch: 9/10 Iteration: 1437 Train loss: 0.000\n",
      "Epoch: 9/10 Iteration: 1438 Train loss: 0.000\n",
      "Epoch: 9/10 Iteration: 1439 Train loss: 0.000\n",
      "Epoch: 9/10 Iteration: 1440 Train loss: 0.000\n",
      "Epoch: 9/10 Iteration: 1441 Train loss: 0.000\n",
      "Epoch: 9/10 Iteration: 1442 Train loss: 0.000\n",
      "Epoch: 9/10 Iteration: 1443 Train loss: 0.002\n",
      "Epoch: 9/10 Iteration: 1444 Train loss: 0.000\n",
      "Epoch: 9/10 Iteration: 1445 Train loss: 0.000\n",
      "Epoch: 9/10 Iteration: 1446 Train loss: 0.000\n",
      "Epoch: 9/10 Iteration: 1447 Train loss: 0.000\n",
      "Epoch: 9/10 Iteration: 1448 Train loss: 0.000\n",
      "Epoch: 9/10 Iteration: 1449 Train loss: 0.000\n",
      "Epoch: 9/10 Iteration: 1450 Train loss: 0.000\n",
      "Val acc: 0.967\n",
      "Epoch: 9/10 Iteration: 1451 Train loss: 0.000\n",
      "Epoch: 9/10 Iteration: 1452 Train loss: 0.000\n",
      "Epoch: 9/10 Iteration: 1453 Train loss: 0.000\n",
      "Epoch: 9/10 Iteration: 1454 Train loss: 0.000\n",
      "Epoch: 9/10 Iteration: 1455 Train loss: 0.000\n",
      "Epoch: 9/10 Iteration: 1456 Train loss: 0.000\n",
      "Epoch: 9/10 Iteration: 1457 Train loss: 0.000\n",
      "Epoch: 9/10 Iteration: 1458 Train loss: 0.000\n",
      "Epoch: 9/10 Iteration: 1459 Train loss: 0.000\n",
      "Epoch: 9/10 Iteration: 1460 Train loss: 0.001\n",
      "Epoch: 9/10 Iteration: 1461 Train loss: 0.000\n",
      "Epoch: 9/10 Iteration: 1462 Train loss: 0.000\n",
      "Epoch: 9/10 Iteration: 1463 Train loss: 0.000\n",
      "Epoch: 9/10 Iteration: 1464 Train loss: 0.000\n",
      "Epoch: 9/10 Iteration: 1465 Train loss: 0.000\n",
      "Epoch: 9/10 Iteration: 1466 Train loss: 0.000\n",
      "Epoch: 9/10 Iteration: 1467 Train loss: 0.000\n",
      "Epoch: 9/10 Iteration: 1468 Train loss: 0.000\n",
      "Epoch: 9/10 Iteration: 1469 Train loss: 0.000\n",
      "Epoch: 9/10 Iteration: 1470 Train loss: 0.000\n",
      "Epoch: 9/10 Iteration: 1471 Train loss: 0.000\n",
      "Epoch: 9/10 Iteration: 1472 Train loss: 0.000\n",
      "Epoch: 9/10 Iteration: 1473 Train loss: 0.000\n",
      "Epoch: 9/10 Iteration: 1474 Train loss: 0.000\n",
      "Epoch: 9/10 Iteration: 1475 Train loss: 0.000\n",
      "Val acc: 0.965\n",
      "Epoch: 9/10 Iteration: 1476 Train loss: 0.000\n",
      "Epoch: 9/10 Iteration: 1477 Train loss: 0.000\n",
      "Epoch: 9/10 Iteration: 1478 Train loss: 0.000\n",
      "Epoch: 9/10 Iteration: 1479 Train loss: 0.000\n",
      "Epoch: 9/10 Iteration: 1480 Train loss: 0.000\n",
      "Epoch: 9/10 Iteration: 1481 Train loss: 0.000\n",
      "Epoch: 9/10 Iteration: 1482 Train loss: 0.000\n",
      "Epoch: 9/10 Iteration: 1483 Train loss: 0.000\n",
      "Epoch: 9/10 Iteration: 1484 Train loss: 0.000\n",
      "Epoch: 9/10 Iteration: 1485 Train loss: 0.000\n",
      "Epoch: 9/10 Iteration: 1486 Train loss: 0.000\n",
      "Epoch: 9/10 Iteration: 1487 Train loss: 0.000\n",
      "Epoch: 9/10 Iteration: 1488 Train loss: 0.000\n",
      "Epoch: 9/10 Iteration: 1489 Train loss: 0.000\n",
      "Epoch: 9/10 Iteration: 1490 Train loss: 0.000\n",
      "Epoch: 9/10 Iteration: 1491 Train loss: 0.000\n",
      "Epoch: 9/10 Iteration: 1492 Train loss: 0.000\n",
      "Epoch: 9/10 Iteration: 1493 Train loss: 0.000\n",
      "Epoch: 9/10 Iteration: 1494 Train loss: 0.000\n",
      "Epoch: 9/10 Iteration: 1495 Train loss: 0.000\n",
      "Epoch: 9/10 Iteration: 1496 Train loss: 0.000\n",
      "Epoch: 9/10 Iteration: 1497 Train loss: 0.000\n",
      "Epoch: 9/10 Iteration: 1498 Train loss: 0.000\n",
      "Epoch: 9/10 Iteration: 1499 Train loss: 0.000\n",
      "Epoch: 9/10 Iteration: 1500 Train loss: 0.000\n",
      "Val acc: 0.967\n",
      "Epoch: 9/10 Iteration: 1501 Train loss: 0.000\n",
      "Epoch: 9/10 Iteration: 1502 Train loss: 0.000\n",
      "Epoch: 9/10 Iteration: 1503 Train loss: 0.000\n",
      "Epoch: 9/10 Iteration: 1504 Train loss: 0.000\n",
      "Epoch: 9/10 Iteration: 1505 Train loss: 0.000\n",
      "Epoch: 9/10 Iteration: 1506 Train loss: 0.000\n",
      "Epoch: 9/10 Iteration: 1507 Train loss: 0.000\n",
      "Epoch: 9/10 Iteration: 1508 Train loss: 0.000\n",
      "Epoch: 9/10 Iteration: 1509 Train loss: 0.000\n",
      "Epoch: 9/10 Iteration: 1510 Train loss: 0.000\n",
      "Epoch: 9/10 Iteration: 1511 Train loss: 0.000\n",
      "Epoch: 9/10 Iteration: 1512 Train loss: 0.000\n",
      "Epoch: 9/10 Iteration: 1513 Train loss: 0.003\n",
      "Epoch: 9/10 Iteration: 1514 Train loss: 0.000\n",
      "Epoch: 9/10 Iteration: 1515 Train loss: 0.000\n",
      "Epoch: 9/10 Iteration: 1516 Train loss: 0.000\n",
      "Epoch: 9/10 Iteration: 1517 Train loss: 0.000\n",
      "Epoch: 9/10 Iteration: 1518 Train loss: 0.000\n",
      "Epoch: 9/10 Iteration: 1519 Train loss: 0.000\n",
      "Epoch: 9/10 Iteration: 1520 Train loss: 0.000\n",
      "Epoch: 9/10 Iteration: 1521 Train loss: 0.000\n",
      "Epoch: 9/10 Iteration: 1522 Train loss: 0.000\n",
      "Epoch: 9/10 Iteration: 1523 Train loss: 0.000\n",
      "Epoch: 9/10 Iteration: 1524 Train loss: 0.000\n",
      "Epoch: 9/10 Iteration: 1525 Train loss: 0.000\n",
      "Val acc: 0.969\n",
      "Epoch: 9/10 Iteration: 1526 Train loss: 0.000\n",
      "Epoch: 9/10 Iteration: 1527 Train loss: 0.000\n",
      "Epoch: 9/10 Iteration: 1528 Train loss: 0.000\n",
      "Epoch: 9/10 Iteration: 1529 Train loss: 0.000\n",
      "Epoch: 9/10 Iteration: 1530 Train loss: 0.000\n",
      "Epoch: 9/10 Iteration: 1531 Train loss: 0.000\n",
      "Epoch: 9/10 Iteration: 1532 Train loss: 0.000\n",
      "Epoch: 9/10 Iteration: 1533 Train loss: 0.000\n",
      "Epoch: 9/10 Iteration: 1534 Train loss: 0.000\n",
      "Epoch: 9/10 Iteration: 1535 Train loss: 0.000\n",
      "Epoch: 9/10 Iteration: 1536 Train loss: 0.000\n",
      "Epoch: 9/10 Iteration: 1537 Train loss: 0.000\n",
      "Epoch: 9/10 Iteration: 1538 Train loss: 0.000\n",
      "Epoch: 9/10 Iteration: 1539 Train loss: 0.000\n",
      "Epoch: 9/10 Iteration: 1540 Train loss: 0.000\n",
      "Epoch: 9/10 Iteration: 1541 Train loss: 0.000\n",
      "Epoch: 9/10 Iteration: 1542 Train loss: 0.001\n",
      "Epoch: 9/10 Iteration: 1543 Train loss: 0.000\n",
      "Epoch: 9/10 Iteration: 1544 Train loss: 0.000\n",
      "Epoch: 9/10 Iteration: 1545 Train loss: 0.000\n",
      "Epoch: 9/10 Iteration: 1546 Train loss: 0.000\n",
      "Epoch: 9/10 Iteration: 1547 Train loss: 0.000\n",
      "Epoch: 9/10 Iteration: 1548 Train loss: 0.000\n",
      "Epoch: 9/10 Iteration: 1549 Train loss: 0.000\n",
      "Epoch: 9/10 Iteration: 1550 Train loss: 0.000\n",
      "Val acc: 0.968\n",
      "Epoch: 9/10 Iteration: 1551 Train loss: 0.000\n",
      "Epoch: 9/10 Iteration: 1552 Train loss: 0.000\n",
      "Epoch: 9/10 Iteration: 1553 Train loss: 0.000\n",
      "Epoch: 9/10 Iteration: 1554 Train loss: 0.000\n",
      "Epoch: 9/10 Iteration: 1555 Train loss: 0.000\n",
      "Epoch: 9/10 Iteration: 1556 Train loss: 0.000\n",
      "Epoch: 9/10 Iteration: 1557 Train loss: 0.000\n",
      "Epoch: 9/10 Iteration: 1558 Train loss: 0.000\n",
      "Epoch: 9/10 Iteration: 1559 Train loss: 0.000\n",
      "Epoch: 9/10 Iteration: 1560 Train loss: 0.000\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "\n",
    "with graph.as_default():\n",
    "    saver = tf.train.Saver()\n",
    "\n",
    "with tf.Session(graph=graph) as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    iteration = 1\n",
    "    for e in range(epochs):\n",
    "        state = sess.run(initial_state)\n",
    "        \n",
    "        for ii, (x, y) in enumerate(get_batches(train_x, train_y, batch_size), 1):\n",
    "            feed = {inputs_: x,\n",
    "                    labels_: y[:, None],\n",
    "                    keep_prob: 0.5,\n",
    "                    initial_state: state}\n",
    "            loss, state, _ = sess.run([cost, final_state, optimizer], feed_dict=feed)\n",
    "            \n",
    "            if iteration%1==0:\n",
    "                print(\"Epoch: {}/{}\".format(e, epochs),\n",
    "                      \"Iteration: {}\".format(iteration),\n",
    "                      \"Train loss: {:.3f}\".format(loss))\n",
    "\n",
    "            if iteration%25==0:\n",
    "                val_acc = []\n",
    "                val_state = sess.run(cell.zero_state(batch_size, tf.float32))\n",
    "                for x, y in get_batches(val_x, val_y, batch_size):\n",
    "                    feed = {inputs_: x,\n",
    "                            labels_: y[:, None],\n",
    "                            keep_prob: 1,\n",
    "                            initial_state: val_state}\n",
    "                    batch_acc, val_state = sess.run([accuracy, final_state], feed_dict=feed)\n",
    "                    val_acc.append(batch_acc)\n",
    "                print(\"Val acc: {:.3f}\".format(np.mean(val_acc)))\n",
    "            iteration +=1\n",
    "    saver.save(sess, \"checkpoints/sentiment.ckpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from checkpoints/sentiment.ckpt\n",
      "Test accuracy: 0.962\n"
     ]
    }
   ],
   "source": [
    "test_acc = []\n",
    "with tf.Session(graph=graph) as sess:\n",
    "    saver.restore(sess, tf.train.latest_checkpoint('checkpoints'))\n",
    "    test_state = sess.run(cell.zero_state(batch_size, tf.float32))\n",
    "    for ii, (x, y) in enumerate(get_batches(test_x, test_y, batch_size), 1):\n",
    "        feed = {inputs_: x,\n",
    "                labels_: y[:, None],\n",
    "                keep_prob: 1,\n",
    "                initial_state: test_state}\n",
    "        batch_acc, test_state = sess.run([accuracy, final_state], feed_dict=feed)\n",
    "        test_acc.append(batch_acc)\n",
    "    print(\"Test accuracy: {:.3f}\".format(np.mean(test_acc)))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
